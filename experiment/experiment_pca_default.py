import streamlit as st
import itertools
import plotly.express as px
import pandas as pd
import numpy as np
import altair as alt
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
import cv2
import csv
import datetime
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import confusion_matrix
from sklearn.linear_model import LinearRegression
from streamlit_option_menu import option_menu
from sklearn.svm import SVC
import joblib
import time
from sklearn.decomposition import PCA

TEST_DATA_RATIO = 0.3
MODEL_PATH = "svm_model.pkl"

def parse_num_list(s, dtype=float):
    """
    '0.1, 1, 10' â†’ [0.1, 1.0, 10.0]
    ç©ºæ–‡å­—ã‚„ä¸æ­£å€¤ã¯ç„¡è¦–ã—ã¾ã™ã€‚dtype ã¯ float / int ã‚’æƒ³å®šã€‚
    """
    if not s:
        return []
    out = []
    for chunk in s.replace("ï¼Œ", ",").split(","):
        chunk = chunk.strip()
        if chunk == "":
            continue
        try:
            out.append(dtype(chunk))
        except Exception:
            pass
    return out

def cv_score_for_params(datas, labels, C, kernel, gamma, degree, coef0, k, max_iter_svc, seed=None):
    """ä¸ãˆã‚‰ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ StratifiedKFold ã®å¹³å‡æ­£è§£ç‡ã‚’è¿”ã™ã€‚"""
    kwargs = dict(C=C, kernel=kernel, max_iter=max_iter_svc)
    if kernel == "linear":
        kwargs.update(gamma="scale", degree=3, coef0=0.0)
    elif kernel == "rbf":
        kwargs.update(gamma=gamma, degree=3, coef0=0.0)
    elif kernel == "poly":
        kwargs.update(gamma=gamma, degree=degree, coef0=coef0)
    elif kernel == "sigmoid":
        kwargs.update(gamma=gamma, degree=3, coef0=coef0)


    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)
    scores = []
    for tr_idx, va_idx in skf.split(datas, labels):
        X_tr, X_va = datas[tr_idx], datas[va_idx]
        y_tr, y_va = labels[tr_idx], labels[va_idx]
        model = SVC(**kwargs)
        model.fit(X_tr, y_tr)
        scores.append(model.score(X_va, y_va))

    avg = float(np.mean(scores))
    return avg, dict(C=C, kernel=kernel, gamma=kwargs["gamma"], degree=kwargs["degree"], coef0=kwargs["coef0"])


# =========================
# UI & ãƒ¡ã‚¤ãƒ³å‡¦ç†
# =========================
def default_pca_experiment():
    st.sidebar.header("æœ€é©åŒ–ã®è¨­å®š")
    kernel = st.sidebar.selectbox("SVMã‚«ãƒ¼ãƒãƒ«", ["rbf", "linear", "poly", "sigmoid"], index=0, help="ä½¿ç”¨ã™ã‚‹ã‚«ãƒ¼ãƒãƒ«")
    k_cv = st.sidebar.slider("StratifiedKFold ã®åˆ†å‰²æ•° (k)", min_value=2, max_value=8, value=5, step=1)
    max_iter_svc = st.sidebar.number_input("SVC ã® max_iter", min_value=-1, max_value=50000, value=1500, step=100)

    st.sidebar.header("æœ€é©åŒ–ã®è¨­å®š")
    # ä¸»æˆåˆ†æ•°ã‚’ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§æŒ‡å®š
    n_components = st.sidebar.slider(
        "ä¸»æˆåˆ†æ•° (n_components)",
        min_value=2,
        max_value=20,     # ã“ã“ã¯è‡ªå‹•çš„ã«åˆ—æ•°ã§ã‚‚OKã«å¤‰æ›´å¯
        value=5,
        step=1
    )

    st.sidebar.header("ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒå€¤")
    C_values = parse_num_list(st.sidebar.text_input("C", value="0.1, 1, 10"), float)

    # ã‚«ãƒ¼ãƒãƒ«åˆ¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    gamma_values = []
    degree_values = []
    coef0_values = []

    if kernel in ["rbf", "poly", "sigmoid"]:
        gamma_values = parse_num_list(st.sidebar.text_input("gamma", value="0.01, 0.05"), float)
    if kernel == "poly":
        degree_values = parse_num_list(st.sidebar.text_input("degree (poly)", value="2, 3"), int)
    if kernel in ["poly", "sigmoid"]:
        coef0_values = parse_num_list(st.sidebar.text_input("coef0 (poly/sigmoid)", value="0.0, 0.5"), float)

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè£œæ­£ï¼ˆç©ºå›é¿ï¼‰
    if not C_values:
        C_values = [1.0]
    if kernel in ["rbf", "poly", "sigmoid"] and not gamma_values:
        gamma_values = [0.01]
    if kernel == "poly" and not degree_values:
        degree_values = [3]
    if kernel in ["poly", "sigmoid"] and not coef0_values:
        coef0_values = [0.0]

    # ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’å®šç¾©
    options = ['æ¬ æå€¤ãƒ‡ãƒ¼ã‚¿å‰Šé™¤', 'ä¸­å¤®å€¤è£œå®Œ', 'å¹³å‡å€¤è£œå®Œ', 'k-NNæ³•è£œå®Œ']

    # ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¸æŠã‚’å–å¾—
    choice_1 = st.sidebar.selectbox('æ¬ æå€¤ã®å¯¾å¿œ', options, index = None, placeholder="é¸æŠã—ã¦ãã ã•ã„")

    # ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’å®šç¾©
    options = ['PainDITECT', 'BS-POP', 'FUSION']

    # ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¸æŠã‚’å–å¾—
    choice_2 = st.sidebar.selectbox('ä½¿ç”¨ã™ã‚‹è³ªå•è¡¨', options, index = None, placeholder="é¸æŠã—ã¦ãã ã•ã„")

    # ==== ãƒ‡ãƒ¼ã‚¿èª­è¾¼ï¼ˆå…ƒãƒ­ã‚¸ãƒƒã‚¯ã‚’è¸è¥²ï¼‰ ====
    if choice_1 == 'æ¬ æå€¤ãƒ‡ãƒ¼ã‚¿å‰Šé™¤' and choice_2 == 'PainDITECT':
        df1 = pd.read_csv('data/null/peindetect/questionnaire_paindetect_missing.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "P1":"P13"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]

    elif choice_1 == 'æ¬ æå€¤ãƒ‡ãƒ¼ã‚¿å‰Šé™¤' and choice_2 == 'BS-POP':
        df1 = pd.read_csv('data/null/BSPOP/questionnaire_bspop_missing.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "D1":"D18"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]

    elif choice_1 == 'æ¬ æå€¤ãƒ‡ãƒ¼ã‚¿å‰Šé™¤' and choice_2 == 'FUSION':
        df1 = pd.read_csv('data/null/fusion/questionnaire_fusion_missing.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "P1":"D18"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]

    elif choice_1 == 'ä¸­å¤®å€¤è£œå®Œ' and choice_2 == 'PainDITECT':
        df1 = pd.read_csv('data/ä¸»æˆåˆ†åˆ†æç”¨/questionnaire_paindetect_median.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "P1":"D13"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]

    elif choice_1 == 'ä¸­å¤®å€¤è£œå®Œ' and choice_2 == 'BS-POP':
        df1 = pd.read_csv('data/ä¸»æˆåˆ†åˆ†æç”¨/questionnaire_bspop_median.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "D1":"D18"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]

    elif choice_1 == 'ä¸­å¤®å€¤è£œå®Œ' and choice_2 == 'FUSION':
        df1 = pd.read_csv('data/ä¸»æˆåˆ†åˆ†æç”¨/questionnaire_fusion_median.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "P1":"D18"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]

    elif choice_1 == 'å¹³å‡å€¤è£œå®Œ' and choice_2 == 'PainDITECT':
        df1 = pd.read_csv('data/ä¸»æˆåˆ†åˆ†æç”¨/questionnaire_paindetect_mean.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "P1":"D13"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]

    elif choice_1 == 'å¹³å‡å€¤è£œå®Œ' and choice_2 == 'BS-POP':
        df1 = pd.read_csv('data/ä¸»æˆåˆ†åˆ†æç”¨/questionnaire_bspop_mean.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "D1":"D18"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]

    elif choice_1 == 'å¹³å‡å€¤è£œå®Œ' and choice_2 == 'FUSION':
        df1 = pd.read_csv('data/ä¸»æˆåˆ†åˆ†æç”¨/questionnaire_fusion_mean.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "P1":"D18"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]

    elif choice_1 == 'k-NNæ³•è£œå®Œ' and choice_2 == 'PainDITECT':
        df1 = pd.read_csv('data/ä¸»æˆåˆ†åˆ†æç”¨/questionnaire_paindetect_knn.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "P1":"D13"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]

    elif choice_1 == 'k-NNæ³•è£œå®Œ' and choice_2 == 'BS-POP':
        df1 = pd.read_csv('data/ä¸»æˆåˆ†åˆ†æç”¨/questionnaire_bspop_knn.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "D1":"D18"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]


    elif choice_1 == 'k-NNæ³•è£œå®Œ' and choice_2 == 'FUSION':
        df1 = pd.read_csv('data/ä¸»æˆåˆ†åˆ†æç”¨/questionnaire_fusion_knn.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "P1":"D18"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]


    options = ['ã™ã‚‹', 'ã—ãªã„']
    choice_4 = st.sidebar.selectbox('ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–', options, index = None, placeholder="é¸æŠã—ã¦ãã ã•ã„")

    X_scaled = None
    feature_names = []

    # æ¨™æº–åŒ–ã®å‡¦ç†ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
    if choice_4 == "ã™ã‚‹":
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

    # --- 4) PCAï¼ˆä¸»æˆåˆ†æ•°ã‚’æŒ‡å®šï¼šä¾‹ 3ã¤ï¼‰ ---
    pca = PCA(n_components)

    if X_scaled is not None:
        X_pca = pca.fit_transform(X_scaled)

        # --- 5) PCAçµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åŒ– ---
        pca_cols = [f"PCA{i+1}" for i in range(n_components)]
        df_pca = pd.DataFrame(X_pca, columns=pca_cols, index=df1.index)

        # --- 6) ç–¼ç—›ç¨®é¡ã‚«ãƒ©ãƒ  + PCAåˆ—ã®æ–°ã—ã„DataFrameã‚’ä½œæˆ ---
        df_pca_final = pd.concat([df1[[pain_col]], df_pca], axis=1)

        feature_names = pca_cols  # PCAåˆ—ã‚’é‡ã¿å¯¾è±¡ã«ã™ã‚‹
        st.success("PCA å®Ÿè¡Œå®Œäº†")

    else:
        st.info("ã¾ã è¨­å®šãŒã•ã‚Œã¦ã„ã¾ã›ã‚“")

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–
    if "weights" not in st.session_state:
        st.session_state.weights = {col: 1.0 for col in feature_names}
    if "reset" not in st.session_state:
        st.session_state.reset = False

    # é‡ã¿ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
    if st.button("é‡ã¿ã‚’ãƒªã‚»ãƒƒãƒˆ", key="weights_reset"):
        for col in feature_names:
            st.session_state.weights[col] = 1.0
        st.session_state.reset = True
        st.success("å…¨ã¦ã®é‡ã¿ã‚’1.0ã«ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚¿ã‚¤ãƒˆãƒ«
    st.sidebar.markdown("### é‡ã¿ä»˜ã‘ï¼ˆPCAåˆ—ï¼‰")

    # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ç”Ÿæˆ
    weights = []
    for col in feature_names:
        if col not in st.session_state.weights:
            st.session_state.weights[col] = 1.0
        default_weight = st.session_state.weights[col]
        weight = st.sidebar.slider(
            f"{col} ã®é‡ã¿",
            min_value=-5.0, max_value=5.0,
            value=default_weight, step=0.1,
            key=f"slider_{col}"
        )
        st.session_state.weights[col] = weight
        weights.append(weight)

    # é‡ã¿ç¢ºèªç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    edited_df = pd.DataFrame({"columns": feature_names, "weights": weights})
    st.write("ç¾åœ¨ã®é‡ã¿ï¼ˆPCAåˆ—ï¼‰")
    st.dataframe(edited_df, use_container_width=True)

    #ãƒ‡ãƒ¼ã‚¿ã®åŠ å·¥æ–¹æ³•ã®æŒ‡å®š
    options = ['æ¬ æå€¤å‰Šé™¤', 'ä¸­å¤®å€¤è£œå®Œ', 'å¹³å‡å€¤è£œå®Œ', 'k-NNæ³•è£œå®Œ']

    # ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¸æŠã‚’å–å¾—
    data_processing = st.sidebar.selectbox('æ¬ æå€¤è£œå®Œã®æ–¹æ³•ã¯ï¼Ÿ', options, index = None, placeholder="é¸æŠã—ã¦ãã ã•ã„")

    if st.button("é–‹å§‹", help="å®Ÿé¨“ã®å®Ÿè¡Œ"):
        start_time = time.time()

        columns = edited_df["columns"].tolist()
        weights = edited_df["weights"].tolist()

        # --- 7) ç–¼ç—›ç¨®é¡ã§3åˆ†å‰² ---
        df_nociceptive = df_pca_final[df_pca_final[pain_col] == "ä¾µå®³å—å®¹æ€§ç–¼ç—›"].copy()
        df_neuropathic = df_pca_final[df_pca_final[pain_col] == "ç¥çµŒéšœå®³æ€§ç–¼ç—›"].copy()
        df_other = df_pca_final[
            ~df_pca_final[pain_col].isin(["ä¾µå®³å—å®¹æ€§ç–¼ç—›", "ç¥çµŒéšœå®³æ€§ç–¼ç—›"])
        ].copy()

        # ãƒ‡ãƒ¼ã‚¿ã®æŒ‡å®š
        df_nociceptive_train = df_nociceptive[columns]
        df_neuronociceptive_train = df_neuropathic[columns]
        df_unknown_train = df_other[columns]

        # é‡ã¿ã‚’é©ç”¨ã—ã¦ç‰¹å¾´é‡ã‚’èª¿æ•´
        df_nociceptive_train_weighted = df_nociceptive_train.mul(weights, axis=1)
        df_neuronociceptive_train_weighted = df_neuronociceptive_train.mul(weights, axis=1)
        df_unknown_train_weighted = df_unknown_train.mul(weights, axis=1)
        
        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã¨ãƒ©ãƒ™ãƒ«ã®ä½œæˆ
        datas = np.vstack(
            [
                df_nociceptive_train_weighted.values,
                df_neuronociceptive_train_weighted.values,
                df_unknown_train_weighted.values,
                ]
                ).astype(np.float32)
        
        labels1 = np.full(len(df_nociceptive_train_weighted), 1, np.int32)
        labels2 = np.full(len(df_neuronociceptive_train_weighted), 2, np.int32)
        labels3 = np.full(len(df_unknown_train_weighted), 3, np.int32)
        labels = np.concatenate([labels1, labels2, labels3]).astype(np.int32)
        
        # æ¨™æº–åŒ–ã®å‡¦ç†ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
        if choice_4 == "ã™ã‚‹":
            scaler = StandardScaler()
            datas = scaler.fit_transform(datas)

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å€™è£œã‚’è¨­å®š
        # === ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§æŒ‡å®šã—ãŸå€™è£œå€¤ã¨ã‚«ãƒ¼ãƒãƒ«ã‚’ä½¿ã£ã¦ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ ===
        # æ—¢ã«ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ C_values / gamma_values / degree_values / coef0_values / kernel / k_cv / max_iter_svc ãŒå®šç¾©æ¸ˆã¿
        best_score = -1.0
        best_params = {}
        best_model = None
        all_results = []

        # çµ„ã¿åˆã‚ã›ã®ç”Ÿæˆï¼ˆã‚«ãƒ¼ãƒãƒ«ã«å¿œã˜ã¦ï¼‰
        param_grid = []
        if kernel == "linear":
            for C in C_values:
                param_grid.append({"C": C})
        elif kernel == "rbf":
            for C in C_values:
                for gamma in gamma_values:
                    param_grid.append({"C": C, "gamma": gamma})
        elif kernel == "poly":
            for C in C_values:
                for gamma in gamma_values:
                    for degree in degree_values:
                        for coef0 in coef0_values:
                            param_grid.append({"C": C, "gamma": gamma, "degree": degree, "coef0": coef0})
        elif kernel == "sigmoid":
            for C in C_values:
                for gamma in gamma_values:
                    for coef0 in coef0_values:
                        param_grid.append({"C": C, "gamma": gamma, "coef0": coef0})

        skf = StratifiedKFold(n_splits=k_cv, shuffle=True, random_state=42)

        # å„çµ„ã¿åˆã‚ã›ã§CVè©•ä¾¡
        for params in param_grid:
            C = params["C"]
            gamma = params.get("gamma", "scale")
            degree = params.get("degree", 3)
            coef0 = params.get("coef0", 0.0)

            scores = []
            for train_index, val_index in skf.split(datas, labels):
                X_train, X_val = datas[train_index], datas[val_index]
                y_train, y_val = labels[train_index], labels[val_index]

                svm = SVC(C=C, kernel=kernel, gamma=gamma, degree=degree, coef0=coef0, max_iter=max_iter_svc)
                svm.fit(X_train, y_train)
                predicted_fold = svm.predict(X_val)
                score = float(np.mean(y_val == predicted_fold))
                scores.append(score)

            avg_score = float(np.mean(scores))

            # ãƒ­ã‚°ç”¨
            all_results.append({
                "kernel": kernel,
                "gamma": gamma if kernel in ["rbf", "poly", "sigmoid"] else None,
                "degree": degree if kernel == "poly" else None,
                "coef0": coef0 if kernel in ["poly", "sigmoid"] else None,
                "C": C,
                "score": avg_score,
                "weights": weights
            })

            if avg_score > best_score:
                best_score = avg_score
                best_params = {"C": C, "gamma": gamma, "degree": degree, "coef0": coef0, "kernel": kernel}
                best_model = svm

        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        joblib.dump(best_model, MODEL_PATH)

        elapsed = time.time() - start_time
        st.write(f"â± å®Ÿè¡Œæ™‚é–“: {elapsed:.2f} ç§’")

        st.subheader("ğŸ“Š ã‚¹ã‚³ã‚¢ã¾ã¨ã‚ï¼ˆé™é †ï¼‰")
        results_df = pd.DataFrame([{
            "kernel": r["kernel"],
            "gamma": r["gamma"],
            "degree": r["degree"],
            "coef0": r["coef0"],
            "C": r["C"],
            "score": r["score"],
            "weights": r["weights"]
        } for r in all_results])
        results_df["score(%)"] = (results_df["score"] * 100).map(lambda x: f"{x:.2f}%")
        st.dataframe(results_df.sort_values(by="score", ascending=False))

        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        svm = joblib.load(MODEL_PATH)
        predicted = svm.predict(X_val)

        st.write(f"âœ… æœ€çµ‚ã‚¹ã‚³ã‚¢: {best_score * 100:.2f}%")
            
        # æ„Ÿåº¦ã¨ç‰¹ç•°åº¦ã®è¨ˆç®—
        conf_matrix = confusion_matrix(y_val, predicted, labels=[1, 2, 3])

        sensitivity_list = []
        specificity_list = []

        n_classes = conf_matrix.shape[0]
        
        for i in range(n_classes):
            TP = conf_matrix[i, i]
            FN = np.sum(conf_matrix[i, :]) - TP
            FP = np.sum(conf_matrix[:, i]) - TP
            TN = np.sum(conf_matrix) - (TP + FN + FP)
            
            sensitivity = TP / (TP + FN) if (TP + FN) != 0 else 0
            specificity = TN / (TN + FP) if (TN + FP) != 0 else 0

            sensitivity_list.append(sensitivity)
            specificity_list.append(specificity)

            st.write(f"ç–¼ç—› {i+1}: æ„Ÿåº¦ = {sensitivity * 100:.2f}%, ç‰¹ç•°åº¦ = {specificity * 100:.2f}%")
            
        # # æ„Ÿåº¦ã¨ç‰¹ç•°åº¦ã®è¡¨ç¤º
        # st.write("æ„Ÿåº¦ã¨ç‰¹ç•°åº¦")
        # st.write("ï¼ˆç–¼ç—›1:ä¾µå®³å—å®¹æ€§ç–¼ç—›,ç–¼ç—›2:ç¥çµŒéšœå®³æ€§ç–¼ç—›,ç–¼ç—›3:ä¸æ˜ï¼‰")
        # for i in range(3):
        #     st.write(f"ç–¼ç—› {i+1}: æ„Ÿåº¦ = {sensitivity[i]:.4f}, ç‰¹ç•°åº¦ = {specificity[i]:.4f}")

        # ç¾åœ¨ã®æ—¥æ™‚ã‚’å–å¾—
        dt_now = datetime.datetime.now()

        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        LOG_FILE_PATH = 'log/LOG_FILE.csv'

        # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’1è¡Œã«ã¾ã¨ã‚ã‚‹
        new_row = {
            'date': dt_now.strftime('%Y%m%d-%H%M%S'),
            'data_processing': data_processing,
            'use_columns': ', '.join(map(str, columns)),
            'weights': ', '.join(map(str, weights)),
            'score': str(best_score*100),
            'sensitivity': ', '.join(f"{x:.4f}" for x in sensitivity_list),
            'specificity': ', '.join(f"{x:.4f}" for x in specificity_list)
        }

        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜ï¼ˆæ—¢å­˜ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ç¶­æŒï¼‰
        with open(LOG_FILE_PATH, mode='a', newline='') as file:
            writer = csv.DictWriter(file, fieldnames=new_row.keys())

            # ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€è¡Œã§è¿½åŠ 
            writer.writerow(new_row)