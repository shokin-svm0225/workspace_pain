import streamlit as st
import itertools
import plotly.express as px
import pandas as pd
import numpy as np
import altair as alt
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
import cv2
import csv
import datetime
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import confusion_matrix
from sklearn.linear_model import LinearRegression
from streamlit_option_menu import option_menu
from sklearn.svm import SVC
import joblib
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
import random
from sklearn.decomposition import PCA

MODEL_PATH = "svm_model.pkl"


st.title('å®Ÿé¨“')

with st.container(border=True):
    col1, col2 = st.columns(2)
# å„ã‚«ãƒ©ãƒ ã«ç”»åƒã‚’è¡¨ç¤º
    with col1:
        # with st.container(border=True):
        st.subheader('å±±ç™»ã‚Šæ³•', divider='rainbow')
        st.markdown("""
        - ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ™ã‚¹ãƒˆ \n
        å„ç‰¹å¾´é‡ã”ã¨ã«ã€Œ+Îµ/-Îµ/Â±0ã®ä¸‰æ–¹å‘ã€ï¼ˆç¾åœ¨ã¾ã§ã®ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢ã‚’è€ƒæ…®ï¼‰ã§æ­£ç­”ç‡ã‚’å‡ºã—ã€3Ã—n(ç‰¹å¾´é‡)é€šã‚Šã®ä¸­ã§ä¸€ç•ªè‰¯ã„æ–¹å‘ã«æ›´æ–°ã—ã¦ã„ã
        """)
    with col2:
        st.code("""
        é‡ã¿ = [1, 1, 1, 1, 1]   â† åˆæœŸçŠ¶æ…‹  
        â†“  
        å„ç‰¹å¾´é‡ã«ã¤ã„ã¦  
            é‡ã¿ + [-Îµ, 0, +Îµ](delta) ã®3é€šã‚Šã‚’è©¦ã™  
            ãƒ»delta = 0 ã®ã¨ãã¯è©•ä¾¡ã›ãšã€ä»Šã®ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢ã‚’ä½¿ã†  
            â†’ ã‚¹ã‚³ã‚¢ãŒæœ€ã‚‚è‰¯ã„é‡ã¿ã‚’è¨˜éŒ²  
        â†“  
        å…¨ç‰¹å¾´é‡ã‚’ä¸€å·¡ã—ãŸã‚‰ä¸€ç•ªè‰¯ã‹ã£ãŸé‡ã¿ã«æ›´æ–°  
        â†“  
        ã“ã‚Œã‚’ max_iter å›ç¹°ã‚Šè¿”ã™
        """, language="text")

# ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’å®šç¾©
options = ['æ¬ æå€¤ãƒ‡ãƒ¼ã‚¿å‰Šé™¤', 'ä¸­å¤®å€¤è£œå®Œ', 'å¹³å‡å€¤è£œå®Œ', 'k-NNæ³•è£œå®Œ']

# ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¸æŠã‚’å–å¾—
choice_1 = st.sidebar.selectbox('æ¬ æå€¤ã®å¯¾å¿œ', options, index = None, placeholder="é¸æŠã—ã¦ãã ã•ã„")

# ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’å®šç¾©
options = ['PainDITECT', 'BS-POP', 'FUSION']

# ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¸æŠã‚’å–å¾—
choice_2 = st.sidebar.selectbox('ä½¿ç”¨ã™ã‚‹è³ªå•è¡¨', options, index = None, placeholder="é¸æŠã—ã¦ãã ã•ã„")

if choice_1 == 'æ¬ æå€¤ãƒ‡ãƒ¼ã‚¿å‰Šé™¤' and choice_2 == 'PainDITECT':
    df1 = pd.read_csv('data/null/peindetect/questionnaire_paindetect_missing.csv', encoding = 'utf-8')
    st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
    st.dataframe(df1)
    X_cols = df1.loc[:, "P1":"D13"].columns.tolist()
    X = df1[X_cols].copy()
    pain_col = df1.columns[1]

elif choice_1 == 'æ¬ æå€¤ãƒ‡ãƒ¼ã‚¿å‰Šé™¤' and choice_2 == 'BS-POP':
    df1 = pd.read_csv('data/null/BSPOP/questionnaire_bspop_missing_ä¾µå®³.csv', encoding = 'utf-8')
    st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
    st.dataframe(df1)
    X_cols = df1.loc[:, "D1":"D18"].columns.tolist()
    X = df1[X_cols].copy()
    pain_col = df1.columns[1]

elif choice_1 == 'æ¬ æå€¤ãƒ‡ãƒ¼ã‚¿å‰Šé™¤' and choice_2 == 'FUSION':
    df1 = pd.read_csv('data/null/fusion/questionnaire_fusion_missing.csv', encoding = 'utf-8')
    st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
    st.dataframe(df1)
    X_cols = df1.loc[:, "P1":"D18"].columns.tolist()
    X = df1[X_cols].copy()
    pain_col = df1.columns[1]

elif choice_1 == 'ä¸­å¤®å€¤è£œå®Œ' and choice_2 == 'PainDITECT':
    df1 = pd.read_csv('data/æ¬ æå€¤è£œå®Œ/PAINDITECT/det_median_ä¾µå®³å—å®¹æ€§ç–¼ç—›_paindetect.csv', encoding = 'utf-8')
    st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
    st.dataframe(df1)
    X_cols = df1.loc[:, "P1":"D13"].columns.tolist()
    X = df1[X_cols].copy()
    pain_col = df1.columns[1]

elif choice_1 == 'ä¸­å¤®å€¤è£œå®Œ' and choice_2 == 'BS-POP':
    df1 = pd.read_csv('data/æ¬ æå€¤è£œå®Œ/BSPOP/det_median_ä¾µå®³å—å®¹æ€§ç–¼ç—›_bspop.csv', encoding = 'utf-8')
    st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
    st.dataframe(df1)
    X_cols = df1.loc[:, "D1":"D18"].columns.tolist()
    X = df1[X_cols].copy()
    pain_col = df1.columns[1]

elif choice_1 == 'ä¸­å¤®å€¤è£œå®Œ' and choice_2 == 'FUSION':
    df1 = pd.read_csv('data/æ¬ æå€¤è£œå®Œ/FUSION/det_median_ä¾µå®³å—å®¹æ€§ç–¼ç—›.csv', encoding = 'utf-8')
    st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
    st.dataframe(df1)
    X_cols = df1.loc[:, "P1":"D18"].columns.tolist()
    X = df1[X_cols].copy()
    pain_col = df1.columns[1]

elif choice_1 == 'å¹³å‡å€¤è£œå®Œ' and choice_2 == 'PainDITECT':
    df1 = pd.read_csv('data/æ¬ æå€¤è£œå®Œ/PAINDITECT/det_mean_ä¾µå®³å—å®¹æ€§ç–¼ç—›_paindetect.csv', encoding = 'utf-8')
    st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
    st.dataframe(df1)
    X_cols = df1.loc[:, "P1":"D13"].columns.tolist()
    X = df1[X_cols].copy()
    pain_col = df1.columns[1]

elif choice_1 == 'å¹³å‡å€¤è£œå®Œ' and choice_2 == 'BS-POP':
    df1 = pd.read_csv('data/æ¬ æå€¤è£œå®Œ/BSPOP/det_mean_ä¾µå®³å—å®¹æ€§ç–¼ç—›_bspop.csv', encoding = 'utf-8')
    st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
    st.dataframe(df1)
    X_cols = df1.loc[:, "D1":"D18"].columns.tolist()
    X = df1[X_cols].copy()
    pain_col = df1.columns[1]

elif choice_1 == 'å¹³å‡å€¤è£œå®Œ' and choice_2 == 'FUSION':
    df1 = pd.read_csv('data/æ¬ æå€¤è£œå®Œ/FUSION/det_mean_ä¾µå®³å—å®¹æ€§ç–¼ç—›.csv', encoding = 'utf-8')
    st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
    st.dataframe(df1)
    X_cols = df1.loc[:, "P1":"D18"].columns.tolist()
    X = df1[X_cols].copy()
    pain_col = df1.columns[1]

elif choice_1 == 'k-NNæ³•è£œå®Œ' and choice_2 == 'PainDITECT':
    df1 = pd.read_csv('data/æ¬ æå€¤è£œå®Œ/PAINDITECT/det_KNN_ä¾µå®³å—å®¹æ€§ç–¼ç—›_paindetect.csv', encoding = 'utf-8')
    st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
    st.dataframe(df1)
    X_cols = df1.loc[:, "P1":"D13"].columns.tolist()
    X = df1[X_cols].copy()
    pain_col = df1.columns[1]

elif choice_1 == 'k-NNæ³•è£œå®Œ' and choice_2 == 'BS-POP':
    df1 = pd.read_csv('data/æ¬ æå€¤è£œå®Œ/BSPOP/det_KNN_ä¾µå®³å—å®¹æ€§ç–¼ç—›_bspop.csv', encoding = 'utf-8')
    st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
    st.dataframe(df1)
    X_cols = df1.loc[:, "D1":"D18"].columns.tolist()
    X = df1[X_cols].copy()
    pain_col = df1.columns[1]


elif choice_1 == 'k-NNæ³•è£œå®Œ' and choice_2 == 'FUSION':
    df1 = pd.read_csv('data/æ¬ æå€¤è£œå®Œ/FUSION/det_KNN_ä¾µå®³å—å®¹æ€§ç–¼ç—›.csv', encoding = 'utf-8')
    st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
    st.dataframe(df1)
    X_cols = df1.loc[:, "P1":"D18"].columns.tolist()
    X = df1[X_cols].copy()
    pain_col = df1.columns[1]

# if choice_2 in ["PainDITECT"]:
#     X_cols = df1.loc[:, "P1":"D13"].columns.tolist()
#     X = df1[X_cols].copy()
#     pain_col = df1.columns[1]

# if choice_2 in ["BS-POP"]:
#     X_cols = df1.loc[:, "D1":"D18"].columns.tolist()
#     X = df1[X_cols].copy()
#     pain_col = df1.columns[1]

# if choice_2 in ["FUSION"]:
#     X_cols = df1.loc[:, "P1":"D18"].columns.tolist()
#     X = df1[X_cols].copy()
#     pain_col = df1.columns[1]

# weights = []

# # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ–
# if "weights" not in st.session_state:
#     st.session_state.weights = {stock: 1.0 for stock in X_cols}
# if "reset" not in st.session_state:
#     st.session_state.reset = False

# # é‡ã¿ã®åˆæœŸåŒ–
# if st.button("é‡ã¿ã‚’ãƒªã‚»ãƒƒãƒˆ", key="weights_reset"):
#     for stock in X_cols:
#         st.session_state.weights[stock] = 1.0  # å…¨ã¦ã®é‡ã¿ã‚’åˆæœŸåŒ–
#     st.session_state.reset = True

# # å‹•çš„ã«ã‚¹ãƒ©ã‚¤ãƒ‰ãƒãƒ¼ã‚’ç”Ÿæˆã—ã€weightsã«æ ¼ç´
# for column in X_cols:
#     if column not in st.session_state.weights:
#         st.session_state.weights[column] = 1.0
#     # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã®åˆæœŸå€¤ã‚’å–å¾—
#     default_weight = st.session_state.weights[column]
#     st.sidebar.markdown("### é‡ã¿ä»˜ã‘")
#     weight = st.sidebar.slider(f"{column}ã®é‡ã¿", min_value=-5.0, max_value=5.0, value=default_weight, step=0.1, key=f"slider_{column}")
#     weights.append(weight)
#     # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã®å€¤ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
#     st.session_state.weights[column] = weight

# # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
# edited_df = pd.DataFrame({"columns": X_cols, "weights": weights})

# # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¡¨ç¤º
# st.dataframe(edited_df)

# st.markdown('#### ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–')
# ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’å®šç¾©
options = ['ã™ã‚‹', 'ã—ãªã„']

# ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¸æŠã‚’å–å¾—
choice_4 = st.sidebar.selectbox('ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–', options, index = None, placeholder="é¸æŠã—ã¦ãã ã•ã„")

#ãƒ‡ãƒ¼ã‚¿ã®åŠ å·¥æ–¹æ³•ã®æŒ‡å®š
options = ['æ¬ æå€¤å‰Šé™¤', 'ä¸­å¤®å€¤è£œå®Œ', 'å¹³å‡å€¤è£œå®Œ', 'k-NNæ³•è£œå®Œ']

# ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¸æŠã‚’å–å¾—
data_processing = st.sidebar.selectbox('æ¬ æå€¤è£œå®Œã®æ–¹æ³•ã¯ï¼Ÿ', options, index = None, placeholder="é¸æŠã—ã¦ãã ã•ã„")


# æ¨™æº–åŒ–ã®å‡¦ç†ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
if choice_4 == "ã™ã‚‹":
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

# --- 4) PCAï¼ˆä¸»æˆåˆ†æ•°ã‚’æŒ‡å®šï¼šä¾‹ 3ã¤ï¼‰ ---
pca = PCA(n_components=3)
X_pca = pca.fit_transform(X_scaled)

# --- 5) PCAçµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åŒ– ---
pca_cols = [f"PCA{i+1}" for i in range(3)]
df_pca = pd.DataFrame(X_pca, columns=pca_cols, index=df1.index)

# --- 6) ç–¼ç—›ç¨®é¡ã‚«ãƒ©ãƒ  + PCAåˆ—ã®æ–°ã—ã„DataFrameã‚’ä½œæˆ ---
df_pca_final = pd.concat([df1[[pain_col]], df_pca], axis=1)

feature_names = pca_cols  # PCAåˆ—ã‚’é‡ã¿å¯¾è±¡ã«ã™ã‚‹

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–
if "weights" not in st.session_state:
    st.session_state.weights = {col: 1.0 for col in feature_names}
if "reset" not in st.session_state:
    st.session_state.reset = False

# é‡ã¿ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
if st.button("é‡ã¿ã‚’ãƒªã‚»ãƒƒãƒˆ", key="weights_reset"):
    for col in feature_names:
        st.session_state.weights[col] = 1.0
    st.session_state.reset = True
    st.success("å…¨ã¦ã®é‡ã¿ã‚’1.0ã«ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚¿ã‚¤ãƒˆãƒ«
st.sidebar.markdown("### é‡ã¿ä»˜ã‘ï¼ˆPCAåˆ—ï¼‰")

# ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ç”Ÿæˆ
weights = []
for col in feature_names:
    if col not in st.session_state.weights:
        st.session_state.weights[col] = 1.0
    default_weight = st.session_state.weights[col]
    weight = st.sidebar.slider(
        f"{col} ã®é‡ã¿",
        min_value=-5.0, max_value=5.0,
        value=default_weight, step=0.1,
        key=f"slider_{col}"
    )
    st.session_state.weights[col] = weight
    weights.append(weight)

# é‡ã¿ç¢ºèªç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
edited_df = pd.DataFrame({"columns": feature_names, "weights": weights})
st.write("ç¾åœ¨ã®é‡ã¿ï¼ˆPCAåˆ—ï¼‰")
st.dataframe(edited_df, use_container_width=True)

if st.button("é–‹å§‹", help="å®Ÿé¨“ã®å®Ÿè¡Œ"):
    columns = edited_df["columns"].tolist()
    weights = edited_df["weights"].tolist()

    # # æ¨™æº–åŒ–ã®å‡¦ç†ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
    # if choice_4 == "ã™ã‚‹":
    #     scaler = StandardScaler()
    #     X_scaled = scaler.fit_transform(X)

    # # --- 4) PCAï¼ˆä¸»æˆåˆ†æ•°ã‚’æŒ‡å®šï¼šä¾‹ 3ã¤ï¼‰ ---
    # pca = PCA(n_components=3)
    # X_pca = pca.fit_transform(X_scaled)

    # # --- 5) PCAçµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åŒ– ---
    # pca_cols = [f"PCA{i+1}" for i in range(3)]
    # df_pca = pd.DataFrame(X_pca, columns=pca_cols, index=df1.index)

    # # --- 6) ç–¼ç—›ç¨®é¡ã‚«ãƒ©ãƒ  + PCAåˆ—ã®æ–°ã—ã„DataFrameã‚’ä½œæˆ ---
    # df_pca_final = pd.concat([df1[[pain_col]], df_pca], axis=1)

    # --- 7) ç–¼ç—›ç¨®é¡ã§3åˆ†å‰² ---
    df_nociceptive = df_pca_final[df_pca_final[pain_col] == "ä¾µå®³å—å®¹æ€§ç–¼ç—›"].copy()
    df_neuropathic = df_pca_final[df_pca_final[pain_col] == "ç¥çµŒéšœå®³æ€§ç–¼ç—›"].copy()
    df_other = df_pca_final[
        ~df_pca_final[pain_col].isin(["ä¾µå®³å—å®¹æ€§ç–¼ç—›", "ç¥çµŒéšœå®³æ€§ç–¼ç—›"])
    ].copy()

    # # é‡ã¿ã®åˆæœŸåŒ–
    # if st.button("é‡ã¿ã‚’ãƒªã‚»ãƒƒãƒˆ", key="weights_reset"):
    #     for stock in X_cols:
    #         st.session_state.weights[stock] = 1.0  # å…¨ã¦ã®é‡ã¿ã‚’åˆæœŸåŒ–
    #     st.session_state.reset = True

    # # å‹•çš„ã«ã‚¹ãƒ©ã‚¤ãƒ‰ãƒãƒ¼ã‚’ç”Ÿæˆã—ã€weightsã«æ ¼ç´
    # for column in X_cols:
    #     if column not in st.session_state.weights:
    #         st.session_state.weights[column] = 1.0
    #     # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã®åˆæœŸå€¤ã‚’å–å¾—
    #     default_weight = st.session_state.weights[column]
    #     st.sidebar.markdown("### é‡ã¿ä»˜ã‘")
    #     weight = st.sidebar.slider(f"{column}ã®é‡ã¿", min_value=-5.0, max_value=5.0, value=default_weight, step=0.1, key=f"slider_{column}")
    #     weights.append(weight)
    #     # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã®å€¤ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
    #     st.session_state.weights[column] = weight
    
    # ãƒ‡ãƒ¼ã‚¿ã®æŒ‡å®š
    df_nociceptive_train = df_nociceptive[columns]
    df_neuronociceptive_train = df_neuropathic[columns]
    df_unknown_train = df_other[columns]

    # é‡ã¿ã‚’é©ç”¨ã—ã¦ç‰¹å¾´é‡ã‚’èª¿æ•´
    df_nociceptive_train_weighted = df_nociceptive_train.mul(weights, axis=1)
    df_neuronociceptive_train_weighted = df_neuronociceptive_train.mul(weights, axis=1)
    df_unknown_train_weighted = df_unknown_train.mul(weights, axis=1)
    
    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã¨ãƒ©ãƒ™ãƒ«ã®ä½œæˆ
    datas = np.vstack(
        [
            df_nociceptive_train_weighted.values,
            df_neuronociceptive_train_weighted.values,
            df_unknown_train_weighted.values,
            ]
            ).astype(np.float32)
    
    labels1 = np.full(len(df_nociceptive_train_weighted), 1, np.int32)
    labels2 = np.full(len(df_neuronociceptive_train_weighted), 2, np.int32)
    labels3 = np.full(len(df_unknown_train_weighted), 3, np.int32)
    labels = np.concatenate([labels1, labels2, labels3]).astype(np.int32)

    initial_weights = np.random.randint(-5, 5, datas.shape[1]).astype(float)

    # é‡ã¿ã‚’ã‹ã‘ã‚‹é–¢æ•°
    def apply_weights(datas, weights_change):
        return datas * weights_change

    # æŒ‡å®šã•ã‚ŒãŸé‡ã¿ã§äº¤å·®æ¤œè¨¼ç²¾åº¦ã‚’è¿”ã™é–¢æ•°
    def evaluate(weights_change, datas, labels, C, k=5, return_best_split=False):
        X_weighted = apply_weights(datas, weights_change)
        skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)
        scores = []

        best_fold_score = 0
        best_X_val, best_y_val, best_pred = None, None, None

        for train_index, val_index in skf.split(X_weighted, labels):
            X_train, X_val = X_weighted[train_index], X_weighted[val_index]
            y_train, y_val = labels[train_index], labels[val_index]

            model = SVC(C=C, kernel='linear', max_iter=1500)
            model.fit(X_train, y_train)
            y_pred = model.predict(X_val)
            acc = np.mean(y_pred == y_val)
            scores.append(acc)

            # è©•ä¾¡æŒ‡æ¨™ãŒæœ€é«˜ã®foldã‚’ä¿å­˜
            if return_best_split and acc > best_fold_score:
                best_fold_score = acc
                best_X_val = X_val
                best_y_val = y_val
                best_pred = y_pred

        if return_best_split:
                return np.mean(scores), best_X_val, best_y_val, best_pred
        else:
            return np.mean(scores)

    # å±±ç™»ã‚Šæ³•ï¼ˆ1ã¤ã®Cã«å¯¾ã—ã¦æœ€é©ãªé‡ã¿ã‚’æ¢ç´¢ï¼‰
    def hill_climbing(datas, labels, C, max_iter_1=1000, step_size=0.01):
        n_features = datas.shape[1]
        weights_change = np.ones(n_features).astype(float)
        # weights_change = initial_weights.copy()  # å¤–ã‹ã‚‰æ¸¡ã•ã‚ŒãŸå›ºå®šã®åˆæœŸé‡ã¿
        st.write("âœ… åˆæœŸé‡ã¿:" + str([int(w) for w in weights_change]))

        best_score, best_X_val, best_y_val, best_pred = evaluate(weights_change, datas, labels, C
        , return_best_split=True)
        best_weights = weights_change.copy()


        # Streamlitã®é€²æ—ãƒãƒ¼ã¨ã‚¹ã‚³ã‚¢è¡¨ç¤º
        hill_bar = st.progress(0)
        score_history = [best_score]


        for i in range(max_iter_1):
            step_best_score = -np.inf 
            candidates = [] 

            for idx in range(n_features):
                for delta in [-step_size, step_size]:
                    trial_weights = weights_change.copy()
                    trial_weights = trial_weights.astype(float)
                    trial_weights[idx] += delta

                    score, X_val_tmp, y_val_tmp, pred_tmp = evaluate(
                        trial_weights, datas, labels, C, return_best_split=True
                    )

                if score > step_best_score:
                    step_best_score = score
                    candidates = [(trial_weights.copy(), X_val_tmp, y_val_tmp, pred_tmp)]  # ğŸ”„ æ–°ã—ãè¨˜éŒ²
                elif score == step_best_score:
                    candidates.append((trial_weights.copy(), X_val_tmp, y_val_tmp, pred_tmp)) 

            # âœ… ã‚¹ã‚³ã‚¢ãŒåŒã˜å€™è£œã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«1ã¤ã‚’é¸ã¶
            selected_weights, selected_X_val, selected_y_val, selected_pred = random.choice(candidates)
            weights_change = selected_weights
            best_weights = weights_change.copy()
            best_score = step_best_score
            best_X_val, best_y_val, best_pred = selected_X_val, selected_y_val, selected_pred


            score_history.append(best_score)
            percent = int((i + 1) / max_iter_1 * 100)
            hill_bar.progress(percent, text=f"é€²æ—çŠ¶æ³{percent}%")

        return best_weights, max(score_history), best_X_val, best_y_val, best_pred, score_history

    C_values = [1, 0.1]
    best_score = 0
    best_C = None
    best_weights = None
    best_X_val = best_y_val = best_pred = None

    # Cã®ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒï¼ˆå¤–å´ãƒ«ãƒ¼ãƒ—ï¼‰
    for C in C_values:
        weights_change, score, X_val_tmp, y_val_tmp, pred_tmp, score_history = hill_climbing(datas, labels, C, max_iter_1=1000, step_size=0.01)
        st.write(f"â†’ C={C} ã§å¾—ã‚‰ã‚ŒãŸã‚¹ã‚³ã‚¢: {score:.4f}")
        # ã‚°ãƒ©ãƒ•æç”»
        fig, ax = plt.subplots()
        ax.plot(score_history)
        ax.set_title("Score progression by Hill Climbing")
        ax.set_xlabel("Step")
        ax.set_ylabel("Score")
        st.pyplot(fig)

        if score > best_score:
            best_score = score
            best_C = C
            best_weights = weights_change
            best_X_val = X_val_tmp
            best_y_val = y_val_tmp
            best_pred = pred_tmp

    # æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ï¼†ä¿å­˜
    X_weighted_final = apply_weights(datas, best_weights)
    final_model = SVC(C=best_C, kernel='linear', max_iter=1500)
    final_model.fit(X_weighted_final, labels)
    joblib.dump(final_model, MODEL_PATH)

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
    best_weights_df = pd.DataFrame({"columns": feature_names, "weights": best_weights})

    # çµæœè¡¨ç¤º
    st.write("âœ… æœ€é©ãªC:", best_C)
    st.write("âœ… æœ€é©ãªé‡ã¿:")
    st.dataframe(best_weights_df)
    st.write("âœ… æœ€çµ‚ã‚¹ã‚³ã‚¢:", best_score)

    # æ„Ÿåº¦ã¨ç‰¹ç•°åº¦ã®è¨ˆç®—
    conf_matrix = confusion_matrix(best_y_val, best_pred, labels=[1, 2, 3])

    sensitivity_list = []
    specificity_list = []

    n_classes = conf_matrix.shape[0]
    
    for i in range(n_classes):
        TP = conf_matrix[i, i]
        FN = np.sum(conf_matrix[i, :]) - TP
        FP = np.sum(conf_matrix[:, i]) - TP
        TN = np.sum(conf_matrix) - (TP + FN + FP)
        
        sensitivity = TP / (TP + FN) if (TP + FN) != 0 else 0
        specificity = TN / (TN + FP) if (TN + FP) != 0 else 0

        sensitivity_list.append(sensitivity)
        specificity_list.append(specificity)

        st.write(f"ç–¼ç—› {i+1}: æ„Ÿåº¦ = {sensitivity * 100:.2f}%, ç‰¹ç•°åº¦ = {specificity * 100:.2f}%")