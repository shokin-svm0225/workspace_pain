import streamlit as st
import itertools
import plotly.express as px
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import altair as alt
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
import cv2
import csv
import datetime
from sklearn.linear_model import LinearRegression
from streamlit_option_menu import option_menu
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

def show_pca_analysis(df, start_col='P1', end_col='D13', pain_col=None):
    # --- åˆ—æŒ‡å®šç¢ºèª ---
    if pain_col is None:
        pain_col = df.columns[1]

    # ==== ç‰¹å¾´é‡æŠ½å‡º ====
    X_full = df.loc[:, start_col:end_col].copy()
    valid_idx = X_full.dropna().index
    X = X_full.loc[valid_idx]
    labels = df.loc[valid_idx, pain_col].astype(str).values

    lab_noci = "ä¾µå®³å—å®¹æ€§ç–¼ç—›"
    lab_neur = "ç¥çµŒéšœå®³æ€§ç–¼ç—›"

    st.subheader("ç›¸é–¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
    corr = X.corr()
    fig1, ax1 = plt.subplots(figsize=(12, 10))
    sns.heatmap(corr, cmap="coolwarm", center=0, annot=False, ax=ax1)
    ax1.set_title("Correlation Heatmap")
    st.pyplot(fig1)

    # ==== æ¨™æº–åŒ– ====
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # ==== PCA ====
    st.subheader("PCAå®Ÿæ–½")
    max_n = min(30, X.shape[1])  # ä¸»æˆåˆ†ã®æœ€å¤§æ•°ï¼ˆå¿…è¦ãªã‚‰å¢—ã‚„ã—ã¦OKï¼‰
    n_components = st.slider("ä¸»æˆåˆ†æ•° (n_components)", min_value=2, max_value=max_n, value=min(15, max_n), step=1)

    pca = PCA(n_components=n_components)
    X_pca = pca.fit_transform(X_scaled)  # â† fit + transform
    pca_cols = [f"PC{i+1}" for i in range(n_components)]

    # ==== ä¸»æˆåˆ†è² è·é‡ï¼ˆãƒ­ãƒ¼ãƒ‰ingsï¼‰ ====
    st.subheader("å„è³ªå•é …ç›®ã®ä¸»æˆåˆ†è² è·é‡ï¼ˆå…ƒã®è³ªå•é …ç›® Ã— ä¸»æˆåˆ†ï¼‰")
    loadings = pd.DataFrame(pca.components_.T, columns=pca_cols, index=X.columns)
    fig2, ax2 = plt.subplots(figsize=(max(10, n_components*0.6), 10))
    sns.heatmap(loadings, annot=True, cmap="coolwarm", center=0, ax=ax2)
    ax2.set_title("Principal Component Loadings")
    ax2.set_xlabel("PCA")
    ax2.set_ylabel("questions")
    st.pyplot(fig2)

    # ==== æ•£å¸ƒå›³ï¼ˆä»»æ„ã®2ä¸»æˆåˆ†ã‚’æ¯”è¼ƒï¼‰ ====
    st.subheader("PCA ã‚¹ã‚³ã‚¢æ•£å¸ƒå›³")
    st.markdown("""
    - âš«ï¸ï¼šä¾µå®³å—å®¹æ€§ç–¼ç—›(nociceptive)
    - â–²ï¼šç¥çµŒéšœå®³æ€§ç–¼ç—›(neuropathic)
    - â—¼ï¸ï¼šä¸æ˜(unknown)
    """)
    # 0å§‹ã¾ã‚Šã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ã†ï¼ˆè¡¨ç¤ºã¯PCç•ªå·ï¼‰
    pc_x_name = st.selectbox("æ¨ªè»¸", pca_cols, index=min(0, n_components-1))
    pc_y_name = st.selectbox("ç¸¦è»¸", pca_cols, index=min(1, n_components-1))
    pc_x = pca_cols.index(pc_x_name)
    pc_y = pca_cols.index(pc_y_name)

    mask_noci = (labels == lab_noci)
    mask_neur = (labels == lab_neur)
    mask_other = ~(mask_noci | mask_neur)

    fig3, ax3 = plt.subplots(figsize=(8, 6))
    ax3.scatter(X_pca[mask_noci, pc_x], X_pca[mask_noci, pc_y], label="nociceptive", alpha=0.8, marker='o')
    ax3.scatter(X_pca[mask_neur, pc_x], X_pca[mask_neur, pc_y], label="neuropathic", alpha=0.8, marker='^')
    ax3.scatter(X_pca[mask_other, pc_x], X_pca[mask_other, pc_y], label="unknown", alpha=0.6, marker='s')
    ax3.set_xlabel(pc_x_name)
    ax3.set_ylabel(pc_y_name)
    ax3.set_title(f"PCA-({pc_x_name} vs {pc_y_name})")
    ax3.legend(loc="best", frameon=True)
    ax3.grid(True, linestyle="--", alpha=0.3)
    st.pyplot(fig3)

    # ==== è£œè¶³æƒ…å ± ====
    st.markdown("**å¯„ä¸ç‡**")
    cumexp = np.cumsum(pca.explained_variance_ratio_)
    st.write(pd.DataFrame({
        "PC": pca_cols,
        "å¯„ä¸ç‡": np.round(pca.explained_variance_ratio_, 4),
        "ç´¯ç©å¯„ä¸ç‡": np.round(cumexp, 4),
    }))



st.title('ãƒ‡ãƒ¼ã‚¿åˆ†æ')

# ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’å®šç¾©
options = ['æ¬ æå€¤ãƒ‡ãƒ¼ã‚¿å‰Šé™¤', 'ä¸­å¤®å€¤è£œå®Œ', 'å¹³å‡å€¤è£œå®Œ', 'k-NNæ³•è£œå®Œ']

options_1 = ['æ¨™æº–åŒ–','ç›¸é–¢ä¿‚æ•°']

# ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
home_type = st.sidebar.radio("é¸ã‚“ã§ãã ã•ã„", ["ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒ", "ãƒ‡ãƒ¼ã‚¿å¤‰æ›", "ä¸»æˆåˆ†åˆ†æ"])

# ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã¨å‡¦ç†
if home_type == "ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒ":
    # ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¸æŠã‚’å–å¾—
    choice_1 = st.selectbox('ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒ', options, index = None, placeholder="é¸æŠã—ã¦ãã ã•ã„")
    if choice_1 == 'æ¬ æå€¤ãƒ‡ãƒ¼ã‚¿å‰Šé™¤':
        df1 = pd.read_csv('data/null/fusion/questionnaire_fusion_missing_ä¾µå®³.csv')
        df2 = pd.read_csv('data/null/fusion/questionnaire_fusion_missing_ç¥çµŒ.csv')
        df3 = pd.read_csv('data/null/fusion/questionnaire_fusion_missing_ä¸æ˜.csv')
    elif choice_1 == 'ä¸­å¤®å€¤è£œå®Œ':
        df1 = pd.read_csv('data/æ¬ æå€¤è£œå®Œ/FUSION/det_median_ä¾µå®³å—å®¹æ€§ç–¼ç—›.csv')
        df2 = pd.read_csv('data/æ¬ æå€¤è£œå®Œ/FUSION/det_median_ç¥çµŒéšœå®³æ€§ç–¼ç—›.csv')
        df3 = pd.read_csv('data/æ¬ æå€¤è£œå®Œ/FUSION/det_median_ä¸æ˜.csv')
    elif choice_1 == 'å¹³å‡å€¤è£œå®Œ':
        df1 = pd.read_csv('data/æ¬ æå€¤è£œå®Œ/FUSION/det_mean_ä¾µå®³å—å®¹æ€§ç–¼ç—›.csv')
        df2 = pd.read_csv('data/æ¬ æå€¤è£œå®Œ/FUSION/det_mean_ç¥çµŒéšœå®³æ€§ç–¼ç—›.csv')
        df3 = pd.read_csv('data/æ¬ æå€¤è£œå®Œ/FUSION/det_mean_ä¸æ˜.csv')
    elif choice_1 == 'k-NNæ³•è£œå®Œ':
        df1 = pd.read_csv('data/æ¬ æå€¤è£œå®Œ/FUSION/det_KNN_ä¾µå®³å—å®¹æ€§ç–¼ç—›.csv')
        df2 = pd.read_csv('data/æ¬ æå€¤è£œå®Œ/FUSION/det_KNN_ç¥çµŒéšœå®³æ€§ç–¼ç—›.csv')
        df3 = pd.read_csv('data/æ¬ æå€¤è£œå®Œ/FUSION/det_KNN_ä¸æ˜.csv')

    # è³ªå•é …ç›®ã®æŠ½å‡º
    question_cols = [col for col in df1.columns if col.startswith('P') or col.startswith('D')]

    # åº¦æ•°åˆ†å¸ƒã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
    def calculate_value_counts(df, columns):
        return pd.DataFrame({col: df[col].value_counts().sort_index() for col in columns}).fillna(0)

    counts_df1 = calculate_value_counts(df1, question_cols)
    counts_df2 = calculate_value_counts(df2, question_cols)
    counts_df3 = calculate_value_counts(df3, question_cols)

    score_range = sorted(set(counts_df1.index).union(counts_df2.index).union(counts_df3.index))

    # 2åˆ—è¡¨ç¤ºï¼ˆmatplotlibã®ã‚°ãƒªãƒƒãƒ‰ã§é…ç½®ï¼‰
    n_cols = 2
    n_rows = int(np.ceil(len(question_cols) / n_cols))
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 3 * n_rows))
    legend_labels = []  # å‡¡ä¾‹ãƒ©ãƒ™ãƒ«ç®¡ç†

    for i, col in enumerate(question_cols):
        r, c = divmod(i, n_cols)
        ax = axes[r][c] if n_cols > 1 else axes[r]
        s_vals = counts_df1[col].reindex(score_range, fill_value=0)
        k_vals = counts_df2[col].reindex(score_range, fill_value=0)
        f_vals = counts_df3[col].reindex(score_range, fill_value=0)

        bar1 = ax.bar(score_range, s_vals, label='Nociceptive Pain', color='navy')
        bar2 = ax.bar(score_range, k_vals, bottom=s_vals, label='Neuropathic Pain', color='skyblue')
        bar3 = ax.bar(score_range, f_vals, bottom=s_vals + k_vals, label='Unknown', color='red')

        if i == 0:
            legend_labels = [bar1[0], bar2[0], bar3[0]]  # æœ€åˆã®ã‚°ãƒ©ãƒ•ã‹ã‚‰ã®ã¿å–å¾—

        ax.set_title(f'{col}')
        ax.set_xlabel('score')
        ax.set_ylabel('people')
        ax.set_xticks(score_range)

    fig.suptitle('Score_distribution[P1-D18]', fontsize=18)
    fig.tight_layout(rect=[0, 0, 1, 0.96])
    fig.legend(legend_labels, ['Nociceptive Pain', 'Neuropathic Pain', 'Unknown'], loc='upper right')

    st.pyplot(fig)

if home_type == "ãƒ‡ãƒ¼ã‚¿å¤‰æ›":
    # ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¸æŠã‚’å–å¾—
    choice_2 = st.selectbox('ãƒ‡ãƒ¼ã‚¿å¤‰æ›', options_1, index = None, placeholder="é¸æŠã—ã¦ãã ã•ã„")
    if choice_2 == 'æ¨™æº–åŒ–':
        st.subheader("ğŸ“‚ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        uploaded_file = st.file_uploader("æ¨™æº–åŒ–ã—ãŸã„CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["csv"])

        if uploaded_file is not None:
            # CSVèª­ã¿è¾¼ã¿
            df = pd.read_csv(uploaded_file)
            # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–
            numeric_cols = df.select_dtypes(include=["float64", "int64"]).columns
            scaler = StandardScaler()
            df_standardized = df.copy()
            df_standardized[numeric_cols] = scaler.fit_transform(df[numeric_cols])
            # ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
            st.subheader("ğŸ“Š æ¨™æº–åŒ–å¾Œã®ãƒ‡ãƒ¼ã‚¿")
            st.dataframe(df_standardized)
    elif choice_2 == 'ç›¸é–¢ä¿‚æ•°':
        st.title("åç›¸é–¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—å¯è¦–åŒ–")
        # --- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ---
        uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type="csv", key="unique_key_all")

        if uploaded_file:
            # === èª­ã¿è¾¼ã¿ & 0,1åˆ—ç›®ã‚’å‰Šé™¤ ===
            df = pd.read_csv(uploaded_file, encoding="utf-8")
            if df.shape[1] < 3:
                st.error("åˆ—æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆæœ€ä½3åˆ—ä»¥ä¸Šå¿…è¦ï¼‰ã€‚")
                st.stop()
            df = df.iloc[:, 2:]  # 0,1åˆ—ç›®ã‚’å‰Šé™¤

            # æ•°å€¤åˆ—ã®ã¿å–ã‚Šå‡ºã—ï¼ˆãƒ†ã‚­ã‚¹ãƒˆåˆ—ç­‰ã¯é™¤å¤–ï¼‰
            df_num = df.select_dtypes(include=[np.number]).copy()

            # å…¨æ¬ æåˆ—ãƒ»å®šæ•°åˆ—ã¯é™¤å¤–ï¼ˆå›å¸°ã§ããªã„ãŸã‚ï¼‰
            nunique = df_num.nunique(dropna=True)
            usable_cols = nunique[nunique > 1].index.tolist()
            df_num = df_num[usable_cols]

            if df_num.shape[1] < 2:
                st.error("åç›¸é–¢ã‚’è¨ˆç®—ã§ãã‚‹æ•°å€¤åˆ—ï¼ˆã‹ã¤å®šæ•°ã§ãªã„åˆ—ï¼‰ãŒ2ã¤ä»¥ä¸Šå¿…è¦ã§ã™ã€‚")
                st.stop()

            st.write("ğŸ§¾ 0,1åˆ—å‰Šé™¤å¾Œã®æ•°å€¤ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼š")
            st.dataframe(df_num.head())

            # === åç›¸é–¢ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°ï¼ˆtarget1 ã¨ target2 ã®ä»–ã‚’åˆ¶å¾¡å¤‰æ•°ã«ï¼‰ ===
            def partial_corr_pairwise(df_, t1, t2, controls):
                cols_needed = [t1, t2] + controls
                d = df_[cols_needed].dropna()
                # ã‚µãƒ³ãƒ—ãƒ«ãŒå°‘ãªã„/åˆ¶å¾¡å¤‰æ•°ãŒå¤šã™ãã‚‹ã¨ä¸å®‰å®šã«ãªã‚‹ãŸã‚ç°¡æ˜“ãƒã‚§ãƒƒã‚¯
                if d.shape[0] < 3 or len(controls) == 0:
                    # controls ãŒç©ºã®ã¨ãã¯é€šå¸¸ã®ç›¸é–¢
                    if len(controls) == 0 and d.shape[0] >= 2:
                        return np.corrcoef(d[t1], d[t2])[0, 1]
                    return np.nan

                # ç·šå½¢å›å¸°ã§æ®‹å·®ã‚’å–ã‚Šå‡ºã™
                try:
                    m1 = LinearRegression().fit(d[controls], d[t1])
                    r1 = d[t1] - m1.predict(d[controls])

                    m2 = LinearRegression().fit(d[controls], d[t2])
                    r2 = d[t2] - m2.predict(d[controls])

                    return np.corrcoef(r1, r2)[0, 1]
                except Exception:
                    return np.nan

            # === åç›¸é–¢è¡Œåˆ—ã®ä½œæˆï¼ˆå…¨ã‚«ãƒ©ãƒ å¯¾è±¡ï¼‰ ===
            vars_all = df_num.columns.tolist()
            n = len(vars_all)
            pcorr = pd.DataFrame(np.eye(n), index=vars_all, columns=vars_all, dtype=float)

            st.write("â³ åç›¸é–¢ã‚’è¨ˆç®—ä¸­...")
            progress = st.progress(0.0)
            total_pairs = n * (n - 1) / 2
            done = 0

            for i in range(n):
                for j in range(i + 1, n):
                    v1, v2 = vars_all[i], vars_all[j]
                    controls = [v for v in vars_all if v not in (v1, v2)]
                    r = partial_corr_pairwise(df_num, v1, v2, controls)
                    pcorr.loc[v1, v2] = r
                    pcorr.loc[v2, v1] = r
                    done += 1
                    progress.progress(done / total_pairs if total_pairs > 0 else 1.0)

            progress.empty()

            # === ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æç”» ===
            st.subheader("ğŸ”¥ åç›¸é–¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆå…¨æ•°å€¤ã‚«ãƒ©ãƒ ï¼‰")
            fig, ax = plt.subplots(figsize=(9, 7))
            sns.heatmap(
                pcorr.astype(float),
                vmin=-1, vmax=1,
                annot=True, fmt=".2f",
                cmap=sns.color_palette("coolwarm", 100)
                # square=True
            )
            ax.set_title("Partial Correlation Matrix (after dropping first two columns)", fontsize=14)
            st.pyplot(fig)

            # === åç›¸é–¢è¡Œåˆ—ã®CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ===
            csv_data = pcorr.round(4).to_csv(index=True).encode("utf-8-sig")
            st.download_button(
                label="ğŸ“¥ åç›¸é–¢è¡Œåˆ—ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv_data,
                file_name="partial_correlation_matrix.csv",
                mime="text/csv"
            )

            # === è¡¨å½¢å¼ã®ç¢ºèª ===
            with st.expander("ğŸ“‹ åç›¸é–¢è¡Œåˆ—ï¼ˆè¡¨å½¢å¼ã§ç¢ºèªï¼‰"):
                st.dataframe(pcorr.round(3))

if home_type == "ä¸»æˆåˆ†åˆ†æ":
    st.header("ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰")

    choice = st.selectbox("ã©ã®ãƒ‡ãƒ¼ã‚¿ã«ã™ã‚‹ï¼Ÿ", ["æ¬ æå€¤å‰Šé™¤(FUSION)", "æ¬ æå€¤å‰Šé™¤(PainDETECT)","æ¬ æå€¤å‰Šé™¤(BS-POP)"])

    if choice == "æ¬ æå€¤å‰Šé™¤(FUSION)":
        df = pd.read_csv("data/null/fusion/questionnaire_fusion_missing.csv")
        show_pca_analysis(df, start_col='P1', end_col='D18', pain_col=None)

    elif choice == "æ¬ æå€¤å‰Šé™¤(PainDETECT)":
        df = pd.read_csv("data/null/peindetect/questionnaire_paindetect_missing.csv")
        show_pca_analysis(df, start_col='P1', end_col='P13', pain_col=None)

    elif choice == "æ¬ æå€¤å‰Šé™¤(BS-POP)":
        df = pd.read_csv("data/null/BSPOP/questionnaire_bspop_missing.csv")
        show_pca_analysis(df, start_col='D1', end_col='D18', pain_col=None)


def show():
    st.title('ãƒ‡ãƒ¼ã‚¿åˆ†æ')
    st.markdown('åç›¸é–¢ä¿‚æ•°ã®è©•ä¾¡ã‚’è¡¨ç¤º')
    st.markdown('#### PainDETECT')
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã®æº–å‚™
    uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv", key="unique_key_1")
    
    # uploadãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã¨ãã ã‘ã€csvãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    if uploaded_file :
        df8 = pd.read_csv(uploaded_file, encoding = 'utf-8')

        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã®2ã¤ã®å¤‰æ•° (target1 ã¨ target2) ã®é–“ã§ã€ä»–ã®å¤‰æ•° (control_vars) ã®å½±éŸ¿ã‚’å–ã‚Šé™¤ã„ãŸåç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—
        def calculate_partial_correlation(df, target1, target2, control_vars):
            # å›å¸°ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆã¨å®Ÿæ¸¬å€¤ã‹ã‚‰äºˆæ¸¬å€¤ã®æ®‹å·®ã®è¨ˆç®—
            model1 = LinearRegression().fit(df[control_vars], df[target1])
            residuals_target1 = df[target1] - model1.predict(df[control_vars])

            model2 = LinearRegression().fit(df[control_vars], df[target2])
            residuals_target2 = df[target2] - model2.predict(df[control_vars])

            # æ®‹å·®é–“ã®ç›¸é–¢ã‚’è¨ˆç®—
            partial_corr = np.corrcoef(residuals_target1, residuals_target2)[0, 1]
            return partial_corr

        # æ–°ã—ã„å¤‰æ•°ãƒªã‚¹ãƒˆã®ä½œæˆï¼ˆP1ã‹ã‚‰P13ã¨D1ã‹ã‚‰D18ï¼‰
        variables = [f'P{i}' for i in range(1, 14)]
        partial_corr_matrix = pd.DataFrame(index=variables, columns=variables)

        # ãƒ«ãƒ¼ãƒ—ã‚’ä½¿ã£ã¦å…¨ã¦ã®ãƒšã‚¢ã§åç›¸é–¢ã‚’è¨ˆç®—
        for i in range(len(variables)):
            for j in range(i + 1, len(variables)):
                target1 = variables[i]
                target2 = variables[j]
                
                # target1ã¨target2ã‚’é™¤ã„ãŸä»–ã®å¤‰æ•°ã‚’åˆ¶å¾¡å¤‰æ•°ã¨ã™ã‚‹
                control_vars = [v for v in variables if v != target1 and v != target2]
                
                # å„ãƒšã‚¢ã®åç›¸é–¢ã‚’è¨ˆç®—
                partial_corr = calculate_partial_correlation(df8, target1, target2, control_vars)
                
                # è¡Œåˆ—ã«å¯¾ç§°çš„ã«æ ¼ç´
                partial_corr_matrix.loc[target1, target2] = partial_corr
                partial_corr_matrix.loc[target2, target1] = partial_corr

        # å¯¾è§’æˆåˆ†ã«1ã‚’è¨­å®šï¼ˆè‡ªå·±ç›¸é–¢ï¼‰
        np.fill_diagonal(partial_corr_matrix.values, 1)

        pd.set_option('display.max_columns', 50)

        # æ•°å€¤ã‚’å°æ•°ç¬¬3ä½ã¾ã§ä¸¸ã‚ã‚‹
        pd.options.display.float_format = '{:.2f}'.format

        # ç¾åœ¨ã®æ—¥æ™‚ã‚’å–å¾—ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«åã«è¿½åŠ 
        timestamp = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')
        output_path = f'/Users/iwasho_0225/Desktop/workspace/pain_experiment/ç›¸é–¢ä¿‚æ•°/PainDETECT/partial_{timestamp}.csv'

        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦å‡ºåŠ›
        partial_corr_matrix.to_csv(output_path, float_format="%.3f")

        # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
        st.success(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒ '{output_path}' ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")

    st.markdown('#### BS-POP')
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã®æº–å‚™
    uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv", key="unique_key_2")
    
    # uploadãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã¨ãã ã‘ã€csvãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    if uploaded_file :
        df8 = pd.read_csv(uploaded_file, encoding = 'utf-8')

        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã®2ã¤ã®å¤‰æ•° (target1 ã¨ target2) ã®é–“ã§ã€ä»–ã®å¤‰æ•° (control_vars) ã®å½±éŸ¿ã‚’å–ã‚Šé™¤ã„ãŸåç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—
        def calculate_partial_correlation(df, target1, target2, control_vars):
            # å›å¸°ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆã¨å®Ÿæ¸¬å€¤ã‹ã‚‰äºˆæ¸¬å€¤ã®æ®‹å·®ã®è¨ˆç®—
            model1 = LinearRegression().fit(df[control_vars], df[target1])
            residuals_target1 = df[target1] - model1.predict(df[control_vars])

            model2 = LinearRegression().fit(df[control_vars], df[target2])
            residuals_target2 = df[target2] - model2.predict(df[control_vars])

            # æ®‹å·®é–“ã®ç›¸é–¢ã‚’è¨ˆç®—
            partial_corr = np.corrcoef(residuals_target1, residuals_target2)[0, 1]
            return partial_corr

        # æ–°ã—ã„å¤‰æ•°ãƒªã‚¹ãƒˆã®ä½œæˆï¼ˆP1ã‹ã‚‰P13ã¨D1ã‹ã‚‰D18ï¼‰
        variables = [f'D{i}' for i in range(1, 19)]
        partial_corr_matrix = pd.DataFrame(index=variables, columns=variables)

        # ãƒ«ãƒ¼ãƒ—ã‚’ä½¿ã£ã¦å…¨ã¦ã®ãƒšã‚¢ã§åç›¸é–¢ã‚’è¨ˆç®—
        for i in range(len(variables)):
            for j in range(i + 1, len(variables)):
                target1 = variables[i]
                target2 = variables[j]
                
                # target1ã¨target2ã‚’é™¤ã„ãŸä»–ã®å¤‰æ•°ã‚’åˆ¶å¾¡å¤‰æ•°ã¨ã™ã‚‹
                control_vars = [v for v in variables if v != target1 and v != target2]
                
                # å„ãƒšã‚¢ã®åç›¸é–¢ã‚’è¨ˆç®—
                partial_corr = calculate_partial_correlation(df8, target1, target2, control_vars)
                
                # è¡Œåˆ—ã«å¯¾ç§°çš„ã«æ ¼ç´
                partial_corr_matrix.loc[target1, target2] = partial_corr
                partial_corr_matrix.loc[target2, target1] = partial_corr

        # å¯¾è§’æˆåˆ†ã«1ã‚’è¨­å®šï¼ˆè‡ªå·±ç›¸é–¢ï¼‰
        np.fill_diagonal(partial_corr_matrix.values, 1)

        pd.set_option('display.max_columns', 50)

        # æ•°å€¤ã‚’å°æ•°ç¬¬3ä½ã¾ã§ä¸¸ã‚ã‚‹
        pd.options.display.float_format = '{:.2f}'.format

        # ç¾åœ¨ã®æ—¥æ™‚ã‚’å–å¾—ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«åã«è¿½åŠ 
        timestamp = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')
        output_path = f'/Users/iwasho_0225/Desktop/workspace/pain_experiment/ç›¸é–¢ä¿‚æ•°/BSPOP/partial_{timestamp}.csv'

        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦å‡ºåŠ›
        partial_corr_matrix.to_csv(output_path, float_format="%.3f")

        # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
        st.success(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒ '{output_path}' ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")

    st.markdown('#### FUSION')
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã®æº–å‚™
    uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv", key="unique_key_3")
    
    # uploadãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã¨ãã ã‘ã€csvãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    if uploaded_file :
        df8 = pd.read_csv(uploaded_file, encoding = 'utf-8')

        def calculate_partial_correlation(df, target1, target2, control_vars):
            model1 = LinearRegression().fit(df[control_vars], df[target1])
            residuals_target1 = df[target1] - model1.predict(df[control_vars])

            model2 = LinearRegression().fit(df[control_vars], df[target2])
            residuals_target2 = df[target2] - model2.predict(df[control_vars])

            partial_corr = np.corrcoef(residuals_target1, residuals_target2)[0, 1]
            return partial_corr

        # æ–°ã—ã„å¤‰æ•°ãƒªã‚¹ãƒˆã®ä½œæˆï¼ˆP1ã‹ã‚‰P13ã¨D1ã‹ã‚‰D18ï¼‰
        variables = [f'P{i}' for i in range(1, 14)] + [f'D{i}' for i in range(1, 19)]
        partial_corr_matrix = pd.DataFrame(index=variables, columns=variables)

        # ãƒ«ãƒ¼ãƒ—ã‚’ä½¿ã£ã¦å…¨ã¦ã®ãƒšã‚¢ã§åç›¸é–¢ã‚’è¨ˆç®—
        for i in range(len(variables)):
            for j in range(i + 1, len(variables)):
                target1 = variables[i]
                target2 = variables[j]
                
                # target1ã¨target2ã‚’é™¤ã„ãŸä»–ã®å¤‰æ•°ã‚’åˆ¶å¾¡å¤‰æ•°ã¨ã™ã‚‹
                control_vars = [v for v in variables if v != target1 and v != target2]
                
                # å„ãƒšã‚¢ã®åç›¸é–¢ã‚’è¨ˆç®—
                partial_corr = calculate_partial_correlation(df8, target1, target2, control_vars)
                
                # è¡Œåˆ—ã«å¯¾ç§°çš„ã«æ ¼ç´
                partial_corr_matrix.loc[target1, target2] = partial_corr
                partial_corr_matrix.loc[target2, target1] = partial_corr

        # å¯¾è§’æˆåˆ†ã«1ã‚’è¨­å®šï¼ˆè‡ªå·±ç›¸é–¢ï¼‰
        np.fill_diagonal(partial_corr_matrix.values, 1)

        pd.set_option('display.max_columns', 50)

        # æ•°å€¤ã‚’å°æ•°ç¬¬3ä½ã¾ã§ä¸¸ã‚ã‚‹
        pd.options.display.float_format = '{:.2f}'.format

        # ç¾åœ¨ã®æ—¥æ™‚ã‚’å–å¾—ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«åã«è¿½åŠ 
        timestamp = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')
        output_path = f'/Users/iwasho_0225/Desktop/workspace/pain_experiment/ç›¸é–¢ä¿‚æ•°/FUSION/partial_{timestamp}.csv'

        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦å‡ºåŠ›
        partial_corr_matrix.to_csv(output_path, float_format="%.3f")

        # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
        st.success(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒ '{output_path}' ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")

    st.markdown('#### ç›¸é–¢ä¿‚æ•°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§')
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã®æº–å‚™
    uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv", key="unique_key_4")

    if uploaded_file:
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
        df = pd.read_csv(uploaded_file)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’å°æ•°ç¬¬3ä½ã¾ã§ä¸¸ã‚ã‚‹
        df = df.round(3)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ã—ã¦å‡ºåŠ›
        st.dataframe(df)