import time
import random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import joblib
import streamlit as st
from joblib import Parallel, delayed
from sklearn.svm import SVC
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import confusion_matrix

# =========================
# å®šæ•°è¨­å®šï¼ˆæœ€å¤§å€¤ã®åˆ¶é™ï¼‰
# =========================
MAX_GAMMA = 10.0
MAX_COEF0 = 10.0

# =========================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ & ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# =========================

def parse_num_list(s, dtype=float):
    """ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šæ–‡å­—åˆ—ã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›"""
    if not s:
        return []
    out = []
    for chunk in s.replace("ï¼Œ", ",").split(","):
        chunk = chunk.strip()
        if chunk == "":
            continue
        try:
            out.append(dtype(chunk))
        except Exception:
            pass
    return out

def apply_weights(datas, weights):
    """ãƒ‡ãƒ¼ã‚¿ã«é‡ã¿ã‚’é©ç”¨ï¼ˆé‡ã¿ã¯å›ºå®šå€¤ï¼‰"""
    return datas * weights

def vec_to_params(vec, kernel):
    """æ¢ç´¢ç”¨ãƒ™ã‚¯ãƒˆãƒ«ã‚’SVMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¾æ›¸ã«å¤‰æ›ã™ã‚‹"""
    p_dict = {"kernel": kernel}
    idx = 0
    p_dict["C"] = vec[idx]
    idx += 1
    if kernel in ["rbf", "poly", "sigmoid"]:
        if idx < len(vec):
            p_dict["gamma"] = vec[idx]
            idx += 1
    if kernel in ["poly", "sigmoid"]:
        if idx < len(vec):
            p_dict["coef0"] = vec[idx]
            idx += 1
    return p_dict

def random_jump_params(params, k, strength, param_types, step_sizes, rng=None):
    """
    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”¨ã®ãƒ©ãƒ³ãƒ€ãƒ ã‚¸ãƒ£ãƒ³ãƒ—ï¼ˆcoef0éè² åˆ¶ç´„ & åŠ ç®—ã‚¸ãƒ£ãƒ³ãƒ— & ä¸Šé™ã‚¬ãƒ¼ãƒ‰å¯¾å¿œç‰ˆï¼‰
    Args:
        step_sizes: å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å±±ç™»ã‚Šæ³•ã§ã®ã‚¹ãƒ†ãƒƒãƒ—å¹…
    """
    rng = np.random.default_rng() if rng is None else rng
    p = np.asarray(params, dtype=float).copy()
    d = len(p)
    k = max(1, min(int(np.ceil(k)), d))
    
    sel = rng.choice(np.arange(d), size=k, replace=False)
    
    for idx in sel:
        if param_types[idx] == 'log':
            # === logã‚¹ã‚±ãƒ¼ãƒ« (C, gamma) ã¯å€ç‡ ===
            noise = rng.uniform(strength[0], strength[1])
            p[idx] *= noise
            p[idx] = max(p[idx], 0.0001) # ä¸‹é™ (æ­£ã®å€¤)
            
            # Gammaã®ä¸Šé™ã‚¬ãƒ¼ãƒ‰ (idx=1 ãŒ gamma ã§ã‚ã‚‹ã¨ä»®å®š)
            if idx == 1: 
                p[idx] = min(p[idx], MAX_GAMMA)

        else:
            # === linearã‚¹ã‚±ãƒ¼ãƒ« (coef0) ã¯åŠ ç®— ===
            scale_factor = 5.0 if strength[1] < 2.0 else 20.0
            
            # step_sizesã‹ã‚‰ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—å¹…ã‚’å–å¾—
            current_step = step_sizes[idx]
            
            jump_val = rng.uniform(-scale_factor, scale_factor) * current_step
            p[idx] += jump_val
            
            # Coef0ã®ä¸‹é™(0)ã¨ä¸Šé™ã‚¬ãƒ¼ãƒ‰
            p[idx] = max(p[idx], 0.0)
            if idx == 2: # idx=2 ãŒ coef0 ã§ã‚ã‚‹ã¨ä»®å®š
                p[idx] = min(p[idx], MAX_COEF0)
                
    return p

# =========================
# è©•ä¾¡é–¢æ•° & æœ€é©åŒ–ãƒ­ã‚¸ãƒƒã‚¯
# =========================

def evaluate_svm_optim(svm_param_vec, fixed_weights, datas, labels, kernel, degree, k=5, return_best_split=False, max_iter_svc=1500):
    """SVMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è©•ä¾¡é–¢æ•°"""
    X_weighted = apply_weights(datas, fixed_weights)
    params = vec_to_params(svm_param_vec, kernel)
    params["degree"] = degree
    params["max_iter"] = max_iter_svc
    
    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)
    scores = []
    best_fold_score = -np.inf
    best_X_val, best_y_val, best_pred = None, None, None

    for train_index, val_index in skf.split(X_weighted, labels):
        X_train, X_val = X_weighted[train_index], X_weighted[val_index]
        y_train, y_val = labels[train_index], labels[val_index]

        model = SVC(**params)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_val)
        acc = np.mean(y_pred == y_val)
        scores.append(acc)

        if return_best_split and acc > best_fold_score:
            best_fold_score = acc
            best_X_val = X_val
            best_y_val = y_val
            best_pred = y_pred

    if return_best_split:
        return np.mean(scores), best_X_val, best_y_val, best_pred
    else:
        return np.mean(scores)

def hill_climbing_svm_params(datas, labels, kernel, degree, fixed_weights, init_params_vec, step_sizes_vec, max_iter_hc=1000, k=5, max_iter_svc=1500, stagnate_L=20, small_strength=(0.85, 1.15), big_strength=(0.4, 2.5)):
    """SVMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹å±±ç™»ã‚Šæ³•"""
    rng = np.random.default_rng()
    current_params = np.array(init_params_vec, dtype=float)
    n_params = len(current_params)
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç¨®é¡ã‚’åˆ¤å®š (é †åº: C -> gamma -> coef0)
    param_types = []
    idx = 0
    param_types.append('log') # C (idx=0)
    idx += 1
    if kernel in ["rbf", "poly", "sigmoid"]:
        if idx < n_params:
            param_types.append('log') # gamma (idx=1)
            idx += 1
    if kernel in ["poly", "sigmoid"]:
        if idx < n_params:
            param_types.append('linear') # coef0 (idx=2)
            idx += 1
    
    best_score, best_X_val, best_y_val, best_pred = evaluate_svm_optim(
        current_params, fixed_weights, datas, labels, kernel, degree, k, True, max_iter_svc
    )
    best_params = current_params.copy()
    score_history = [best_score]
    
    global_best_score = best_score
    global_best_params = best_params.copy()
    global_best_pack = (best_X_val, best_y_val, best_pred)
    
    no_improve = 0
    
    for _ in range(max_iter_hc):
        step_best_score = -np.inf
        candidates = []
        
        for idx in range(n_params):
            step_val = step_sizes_vec[idx]
            
            if param_types[idx] == 'log':
                # å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆå€ç‡ï¼‰
                vals_to_try = [
                    best_params[idx] * step_val,
                    best_params[idx] / step_val
                ]
            else:
                # ç·šå½¢ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆåŠ æ¸›ç®—ï¼‰
                vals_to_try = [
                    best_params[idx] + step_val,
                    best_params[idx] - step_val
                ]

            for val in vals_to_try:
                trial_params = best_params.copy()
                trial_params[idx] = val
                
                # === åˆ¶ç´„å‡¦ç† (ä¸‹é™ & ä¸Šé™) ===
                if param_types[idx] == 'log':
                     trial_params[idx] = max(trial_params[idx], 0.0001)
                     # Gamma (idx=1) ã®ä¸Šé™
                     if idx == 1:
                         trial_params[idx] = min(trial_params[idx], MAX_GAMMA)
                else:
                     # Coef0 (idx=2) ã®éè² åˆ¶ç´„ & ä¸Šé™
                     trial_params[idx] = max(trial_params[idx], 0.0)
                     if idx == 2:
                         trial_params[idx] = min(trial_params[idx], MAX_COEF0)
                
                score, Xv, yv, pr = evaluate_svm_optim(
                    trial_params, fixed_weights, datas, labels, kernel, degree, k, True, max_iter_svc
                )
                
                if score > step_best_score:
                    step_best_score = score
                    candidates = [(trial_params, Xv, yv, pr)]
                elif score == step_best_score:
                    candidates.append((trial_params, Xv, yv, pr))
        
        if step_best_score >= best_score:
            sel_p, sel_Xv, sel_yv, sel_pr = random.choice(candidates)
            best_params = sel_p
            best_score = step_best_score
            best_X_val, best_y_val, best_pred = sel_Xv, sel_yv, sel_pr
            
            if best_score > global_best_score:
                global_best_score = best_score
                global_best_params = best_params.copy()
                global_best_pack = (best_X_val, best_y_val, best_pred)
                no_improve = 0
            else:
                no_improve += 1
        else:
            no_improve += 1
            
        # === åœæ»æ™‚ã®ã‚¸ãƒ£ãƒ³ãƒ—å‡¦ç† ===
        if no_improve >= stagnate_L:
            
            # â˜…å°ã‚¸ãƒ£ãƒ³ãƒ—ã§ã‚‚å¤§ã‚¸ãƒ£ãƒ³ãƒ—ã§ã‚‚ã€å¸¸ã«ã€Œå…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ã‚’å‹•ã‹ã™
            jump_k = n_params 
            
            if no_improve >= stagnate_L * 2:
                # === å¤§ã‚¸ãƒ£ãƒ³ãƒ— (å¼·åº¦: big, å€‹æ•°: å…¨éƒ¨) ===
                best_params = random_jump_params(
                    best_params, k=jump_k, strength=big_strength, 
                    param_types=param_types, step_sizes=step_sizes_vec, rng=rng
                )
                no_improve = 0 # ãƒªã‚»ãƒƒãƒˆ
            else:
                # === å°ã‚¸ãƒ£ãƒ³ãƒ— (å¼·åº¦: small, å€‹æ•°: å…¨éƒ¨) ===
                best_params = random_jump_params(
                    best_params, k=jump_k, strength=small_strength, 
                    param_types=param_types, step_sizes=step_sizes_vec, rng=rng
                )
        
        score_history.append(best_score)
        
    return global_best_params, global_best_score, global_best_pack, score_history

def run_hill_svm_wrapper(kernel, degree, fixed_weights, init_params, step_sizes, datas, labels, max_iter_hc, k_cv, max_iter_svc, stagnate_L):
    """ä¸¦åˆ—å‡¦ç†ç”¨ã®ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°"""
    best_params, score, pack, history = hill_climbing_svm_params(
        datas, labels, kernel, degree, fixed_weights, init_params, step_sizes,
        max_iter_hc=max_iter_hc, k=k_cv, max_iter_svc=max_iter_svc, stagnate_L=stagnate_L
    )
    return {
        "kernel": kernel,
        "degree": degree,
        "best_params_vec": best_params,
        "score": score,
        "history": history,
        "pack": pack
    }

# =========================
# UI & ãƒ¡ã‚¤ãƒ³å‡¦ç†
# =========================

if __name__ == "__main__":
    st.sidebar.header("SVMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–è¨­å®š")

    # 1. ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠ
    kernel = st.sidebar.selectbox("SVMã‚«ãƒ¼ãƒãƒ«", ["linear", "rbf", "poly", "sigmoid"], index=1)

    # â˜…â˜…â˜… åˆæœŸå€¤å€™è£œã®è¨­å®šï¼ˆUIè¿½åŠ ï¼‰ â˜…â˜…â˜…
    st.sidebar.markdown("---")
    st.sidebar.markdown("**åˆæœŸå€¤å€™è£œï¼ˆãƒãƒ«ãƒã‚¹ã‚¿ãƒ¼ãƒˆç”¨ï¼‰**")
    st.sidebar.caption("ãƒ¯ãƒ¼ã‚«ãƒ¼ã”ã¨ã«ã“ã®ãƒªã‚¹ãƒˆã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«åˆæœŸå€¤ã‚’é¸ã³ã¾ã™ã€‚ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    
    c_candidates_str = st.sidebar.text_input("C åˆæœŸå€¤å€™è£œ", "0.1, 1, 10.0")
    
    gamma_candidates_str = "0.01, 0.1, 0.3"
    coef0_candidates_str = "0.0, 1.0, 5.0"

    if kernel in ["rbf", "poly", "sigmoid"]:
        gamma_candidates_str = st.sidebar.text_input("Gamma åˆæœŸå€¤å€™è£œ", "0.01, 0.1, 0.3")
    if kernel in ["poly", "sigmoid"]:
        coef0_candidates_str = st.sidebar.text_input("Coef0 åˆæœŸå€¤å€™è£œ", "0.0, 1.0, 5.0")

    candidates_C = parse_num_list(c_candidates_str)
    candidates_gamma = parse_num_list(gamma_candidates_str)
    candidates_coef0 = parse_num_list(coef0_candidates_str)
    
    if not candidates_C: candidates_C = [1.0]
    if not candidates_gamma: candidates_gamma = [0.1]
    if not candidates_coef0: candidates_coef0 = [0.0]


    st.sidebar.markdown("---")
    st.sidebar.markdown("**å±±ç™»ã‚Šæ³•ã®ã‚¹ãƒ†ãƒƒãƒ—å¹…è¨­å®š**")
    
    step_C = st.sidebar.number_input("Step Rate (C) â€»å€ç‡", value=1.5, step=0.1, help="2.0ãªã‚‰ 1â†’2â†’4 ã¾ãŸã¯ 1â†’0.5â†’0.25")

    step_gamma = 1.5
    step_coef0 = 0.1

    if kernel in ["rbf", "poly", "sigmoid"]:
        step_gamma = st.sidebar.number_input("Step Rate (gamma) â€»å€ç‡", value=1.5, step=0.1, format="%.2f")
    if kernel in ["poly", "sigmoid"]:
        step_coef0 = st.sidebar.number_input("Step Size (coef0) â€»åŠ ç®—", value=0.5, step=0.05)

    st.sidebar.markdown("---")
    max_iter_hc = st.sidebar.number_input("å±±ç™»ã‚Šæ³•ã®åå¾©å›æ•°", min_value=10, max_value=5000, value=1000, step=50)
    
    # åœæ»åˆ¤å®šã®UIå…¥åŠ›ã‚’å¤‰æ•°ã«æ ¼ç´ã™ã‚‹ï¼ˆãƒã‚°ä¿®æ­£æ¸ˆã¿ï¼‰
    stagnate_L = st.sidebar.number_input("åœæ»åˆ¤å®šã‚¹ãƒ†ãƒƒãƒ— L", min_value=5, max_value=200, value=10)
    
    k_cv = st.sidebar.slider("CVåˆ†å‰²æ•° (k)", 2, 10, 5)

    st.sidebar.markdown("---")
    n_components = st.sidebar.slider("PCAä¸»æˆåˆ†æ•°", 2, 20, 5)
    
    # ä¸¦åˆ—æ•°
    st.sidebar.markdown("---")
    n_workers = st.sidebar.slider("ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ï¼ˆã‚¹ã‚¿ãƒ¼ãƒˆåœ°ç‚¹ã®æ•°ï¼‰", 1, 8, 4, help="æ¢ç´¢ã‚’é–‹å§‹ã™ã‚‹åˆæœŸåœ°ç‚¹ã®æ•°ã§ã™ã€‚")

    # ==== ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®š (æ—¢å­˜ã‚³ãƒ¼ãƒ‰ç¶­æŒ) ====
    st.sidebar.header("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®š")
    options_miss = ['æ¬ æå€¤ãƒ‡ãƒ¼ã‚¿å‰Šé™¤', 'ä¸­å¤®å€¤è£œå®Œ', 'å¹³å‡å€¤è£œå®Œ', 'k-NNæ³•è£œå®Œ']
    choice_1 = st.sidebar.selectbox('æ¬ æå€¤ã®å¯¾å¿œ', options_miss, index=None, placeholder="é¸æŠã—ã¦ãã ã•ã„")

    options_sheet = ['PainDITECT', 'BS-POP', 'FUSION']
    choice_2 = st.sidebar.selectbox('ä½¿ç”¨ã™ã‚‹è³ªå•è¡¨', options_sheet, index=None, placeholder="é¸æŠã—ã¦ãã ã•ã„")

    # -- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ --
    if choice_1 == 'æ¬ æå€¤ãƒ‡ãƒ¼ã‚¿å‰Šé™¤' and choice_2 == 'PainDITECT':
        df1 = pd.read_csv('data/null/peindetect/questionnaire_paindetect_missing.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "P1":"P13"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]
    elif choice_1 == 'æ¬ æå€¤ãƒ‡ãƒ¼ã‚¿å‰Šé™¤' and choice_2 == 'BS-POP':
        df1 = pd.read_csv('data/null/BSPOP/questionnaire_bspop_missing.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "D1":"D18"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]
    elif choice_1 == 'æ¬ æå€¤ãƒ‡ãƒ¼ã‚¿å‰Šé™¤' and choice_2 == 'FUSION':
        df1 = pd.read_csv('data/null/fusion/questionnaire_fusion_missing.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "P1":"D18"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]
    elif choice_1 == 'ä¸­å¤®å€¤è£œå®Œ' and choice_2 == 'PainDITECT':
        df1 = pd.read_csv('data/ä¸»æˆåˆ†åˆ†æç”¨/questionnaire_paindetect_median.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "P1":"D13"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]
    elif choice_1 == 'ä¸­å¤®å€¤è£œå®Œ' and choice_2 == 'BS-POP':
        df1 = pd.read_csv('data/ä¸»æˆåˆ†åˆ†æç”¨/questionnaire_bspop_median.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "D1":"D18"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]
    elif choice_1 == 'ä¸­å¤®å€¤è£œå®Œ' and choice_2 == 'FUSION':
        df1 = pd.read_csv('data/ä¸»æˆåˆ†åˆ†æç”¨/questionnaire_fusion_median.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "P1":"D18"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]
    elif choice_1 == 'å¹³å‡å€¤è£œå®Œ' and choice_2 == 'PainDITECT':
        df1 = pd.read_csv('data/ä¸»æˆåˆ†åˆ†æç”¨/questionnaire_paindetect_mean.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "P1":"D13"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]
    elif choice_1 == 'å¹³å‡å€¤è£œå®Œ' and choice_2 == 'BS-POP':
        df1 = pd.read_csv('data/ä¸»æˆåˆ†åˆ†æç”¨/questionnaire_bspop_mean.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "D1":"D18"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]
    elif choice_1 == 'å¹³å‡å€¤è£œå®Œ' and choice_2 == 'FUSION':
        df1 = pd.read_csv('data/ä¸»æˆåˆ†åˆ†æç”¨/questionnaire_fusion_mean.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "P1":"D18"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]
    elif choice_1 == 'k-NNæ³•è£œå®Œ' and choice_2 == 'PainDITECT':
        df1 = pd.read_csv('data/ä¸»æˆåˆ†åˆ†æç”¨/questionnaire_paindetect_knn.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "P1":"D13"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]
    elif choice_1 == 'k-NNæ³•è£œå®Œ' and choice_2 == 'BS-POP':
        df1 = pd.read_csv('data/ä¸»æˆåˆ†åˆ†æç”¨/questionnaire_bspop_knn.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "D1":"D18"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]
    elif choice_1 == 'k-NNæ³•è£œå®Œ' and choice_2 == 'FUSION':
        df1 = pd.read_csv('data/ä¸»æˆåˆ†åˆ†æç”¨/questionnaire_fusion_knn.csv', encoding = 'utf-8')
        st.markdown('#### ãƒ‡ãƒ¼ã‚¿')
        st.dataframe(df1)
        X_cols = df1.loc[:, "P1":"D18"].columns.tolist()
        X = df1[X_cols].copy()
        pain_col = df1.columns[1]
    else:
        st.stop()

    # --- ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç† ---
    options_std = ['ã™ã‚‹', 'ã—ãªã„']
    choice_4 = st.sidebar.selectbox('ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–', options_std, index=None, placeholder="é¸æŠã—ã¦ãã ã•ã„")

    if choice_4 is None:
        st.stop()

    if choice_4 == "ã™ã‚‹":
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
    else:
        X_scaled = X.copy()

    # PCA
    pca = PCA(n_components, svd_solver="full")
    X_pca = pca.fit_transform(X_scaled)
    pca_cols = [f"PCA{i+1}" for i in range(n_components)]
    df_pca = pd.DataFrame(X_pca, columns=pca_cols, index=df1.index)

    # çµåˆ
    df_pca_final = pd.concat([df1[[pain_col]], df_pca], axis=1)
    feature_names = pca_cols

    st.success("PCA å®Ÿè¡Œå®Œäº†")

    # ==== é‡ã¿è¨­å®š ====
    st.sidebar.markdown("### ç‰¹å¾´é‡ã®é‡ã¿ (å›ºå®š)")
    if "weights" not in st.session_state:
        st.session_state.weights = {col: 1.0 for col in feature_names}

    if st.button("é‡ã¿ã‚’ãƒªã‚»ãƒƒãƒˆ", key="weights_reset"):
        for col in feature_names:
            st.session_state.weights[col] = 1.0
        st.success("å…¨ã¦ã®é‡ã¿ã‚’1.0ã«ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")

    weights_list = []
    for col in feature_names:
        val = st.sidebar.slider(f"{col} weight", -5.0, 5.0, st.session_state.weights.get(col, 1.0), 0.1, key=f"w_{col}")
        st.session_state.weights[col] = val
        weights_list.append(val)
        
    fixed_weights = np.array(weights_list)

    st.info("ğŸ’¡ ä¸Šè¨˜ã®ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§è¨­å®šã—ãŸé‡ã¿ã¯ã€Œå›ºå®šã€ã•ã‚Œã€SVMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ã‚’æœ€é©åŒ–ã—ã¾ã™ã€‚")

    # =========================
    # å®Ÿè¡Œãƒœã‚¿ãƒ³
    # =========================
    if st.button("SVMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã‚’é–‹å§‹"):
        
        # 1. ãƒ‡ãƒ¼ã‚¿æº–å‚™
        df_nociceptive = df_pca_final[df_pca_final[pain_col] == "ä¾µå®³å—å®¹æ€§ç–¼ç—›"]
        df_neuropathic = df_pca_final[df_pca_final[pain_col] == "ç¥çµŒéšœå®³æ€§ç–¼ç—›"]
        df_other = df_pca_final[~df_pca_final[pain_col].isin(["ä¾µå®³å—å®¹æ€§ç–¼ç—›", "ç¥çµŒéšœå®³æ€§ç–¼ç—›"])]
        
        X1 = df_nociceptive[feature_names].values
        X2 = df_neuropathic[feature_names].values
        X3 = df_other[feature_names].values
        
        datas = np.vstack([X1, X2, X3]).astype(np.float32)
        
        l1 = np.full(len(X1), 1, dtype=int)
        l2 = np.full(len(X2), 2, dtype=int)
        l3 = np.full(len(X3), 3, dtype=int)
        labels = np.concatenate([l1, l2, l3])

        st.title("ğŸ§  SVMãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–")
        st.write(f"ã‚«ãƒ¼ãƒãƒ«: **{kernel}**")
        st.write("æ¢ç´¢æ–¹å¼: **Degree(æ¬¡æ•°)ã¯ç·å½“ãŸã‚Šã€C/Gammaç­‰ã¯å±±ç™»ã‚Šæ³•ï¼ˆãƒãƒ«ãƒã‚¹ã‚¿ãƒ¼ãƒˆï¼‰** ã§ä¸¦åˆ—æ¢ç´¢ã—ã¾ã™ã€‚")

        # 2. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆæœŸå€¤ã®å€™è£œï¼ˆUIã‹ã‚‰å–å¾—ï¼‰
        step_vec = [step_C]
        param_names = ["C"]
        
        if kernel in ["rbf", "poly", "sigmoid"]:
            step_vec.append(step_gamma)
            param_names.append("gamma")
        
        if kernel in ["poly", "sigmoid"]:
            step_vec.append(step_coef0)
            param_names.append("coef0")
            
        # 3. ä¸¦åˆ—ã‚¿ã‚¹ã‚¯ã®ç”Ÿæˆ
        if kernel == "poly":
            candidate_degrees = [2, 3]
        else:
            candidate_degrees = [3] # rbfç­‰ã§ã¯ãƒ€ãƒŸãƒ¼
            
        futures_input = []
        
        import itertools
        cycle_degrees = itertools.cycle(candidate_degrees)
        
        for _ in range(n_workers):
            d = next(cycle_degrees)
            
            # â˜…â˜…â˜… ãƒ©ãƒ³ãƒ€ãƒ ãªåˆæœŸä½ç½®ã®é¸æŠï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šãƒªã‚¹ãƒˆã‹ã‚‰é¸ã¶ï¼‰ â˜…â˜…â˜…
            start_C = random.choice(candidates_C)
            
            this_init_list = [start_C]
            
            if kernel in ["rbf", "poly", "sigmoid"]:
                start_gamma = random.choice(candidates_gamma)
                this_init_list.append(start_gamma)
                
            if kernel in ["poly", "sigmoid"]:
                start_coef0 = random.choice(candidates_coef0)
                this_init_list.append(start_coef0)
            
            this_init = np.array(this_init_list)
            
            # åˆæœŸå€¤ã«å¾®å°ãƒã‚¤ã‚ºã‚’åŠ ãˆã‚‹ (log/linearå…±é€šã§ç°¡æ˜“çš„ã«å€ç‡ãƒã‚¤ã‚º)
            this_init = this_init * np.random.uniform(0.8, 1.2, len(this_init))
            
            # çµ¶å¯¾å€¤ã‚¬ãƒ¼ãƒ‰ (åˆæœŸå€¤ç”Ÿæˆæ™‚)
            this_init[0] = max(this_init[0], 0.0001) # C
            if kernel in ["rbf", "poly", "sigmoid"]:
                this_init[1] = max(this_init[1], 0.0001) # Gamma
                this_init[1] = min(this_init[1], MAX_GAMMA) # ä¸Šé™ã‚¬ãƒ¼ãƒ‰
            if kernel in ["poly", "sigmoid"]:
                # Coef0ã¯3ç•ªç›®(index=2)
                this_init[2] = max(this_init[2], 0.0) # ä¸‹é™
                this_init[2] = min(this_init[2], MAX_COEF0) # ä¸Šé™ã‚¬ãƒ¼ãƒ‰
            
            futures_input.append({
                "degree": d,
                "init": this_init
            })

        st.write(f"æ¢ç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {param_names}")
        st.write(f"æ¢ç´¢Degreeå€™è£œ: {candidate_degrees if kernel=='poly' else '-(å›ºå®š)'}")
        st.info(f"ä¸¦åˆ—å‡¦ç†ã«ãŠã‘ã‚‹ã‚¹ã‚¿ãƒ¼ãƒˆåœ°ç‚¹ã®æ•° {n_workers} å€‹ãŒã€æŒ‡å®šã•ã‚ŒãŸåˆæœŸå€¤ãƒªã‚¹ãƒˆã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«é¸ã‚“ã§å±±ç™»ã‚Šã‚’é–‹å§‹ã—ã¾ã™ã€‚")
        
        # 4. ä¸¦åˆ—å®Ÿè¡Œ (joblib)
        best_overall_score = -np.inf
        best_overall_result = None
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        total_tasks = len(futures_input)
        
        results_generator = Parallel(n_jobs=n_workers, return_as="generator")(
            delayed(run_hill_svm_wrapper)(
                kernel,
                inp["degree"],
                fixed_weights,
                inp["init"],
                step_vec,
                datas, labels,
                max_iter_hc, k_cv, 1500, stagnate_L
            ) for inp in futures_input
        )
        
        completed_count = 0
        for res in results_generator:
            completed_count += 1
            progress_bar.progress(completed_count / total_tasks)
            
            if res["score"] > best_overall_score:
                best_overall_score = res["score"]
                best_overall_result = res
                
                degree_msg = f"(Degree={res['degree']})" if kernel == "poly" else ""
                status_text.write(f"æš«å®š1ä½æ›´æ–°: Score={best_overall_score:.4f} {degree_msg}")
        
        # 5. çµæœè¡¨ç¤º
        st.success("æ¢ç´¢å®Œäº†ï¼")
        st.markdown(f"### ğŸ† æœ€é«˜æ­£ç­”ç‡: **{best_overall_score*100:.2f}%**")
        
        best_vec = best_overall_result["best_params_vec"]
        best_degree = best_overall_result["degree"]
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¾©å…ƒ
        final_params = vec_to_params(best_vec, kernel)

        if kernel == "poly":
            final_params["degree"] = best_degree
        else:
            final_params["degree"] = "ãªã—"
        
        col1, col2 = st.columns(2)
        with col1:
            st.json(final_params)
        with col2:
            st.write("æœ€çµ‚é‡ã¿")
            st.dataframe(pd.DataFrame([fixed_weights], columns=feature_names))

        # å±¥æ­´ã‚°ãƒ©ãƒ•
        fig, ax = plt.subplots()
        ax.plot(best_overall_result["history"], label="Score History")
        ax.set_title("Optimization History (Best Thread)")
        ax.set_xlabel("Step")
        ax.set_ylabel("Accuracy")
        ax.legend()
        st.pyplot(fig)
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        final_X = apply_weights(datas, fixed_weights)
        
        # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ç”¨
        model_params = vec_to_params(best_vec, kernel)
        model_params["degree"] = best_degree
        
        final_model = SVC(**model_params)
        final_model.fit(final_X, labels)
        joblib.dump(final_model, "optimized_svm_model.joblib")
        st.success("ãƒ¢ãƒ‡ãƒ«ã‚’ 'optimized_svm_model.joblib' ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

        # è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        best_y_val = best_overall_result["pack"][1]
        best_pred = best_overall_result["pack"][2]

        # æ„Ÿåº¦ãƒ»ç‰¹ç•°åº¦ã®è¨ˆç®—ã®ãŸã‚ã«æ··åŒè¡Œåˆ—è‡ªä½“ã¯å†…éƒ¨ã§ä½œã‚‹
        cm = confusion_matrix(best_y_val, best_pred, labels=[1, 2, 3])

        # ã‚¯ãƒ©ã‚¹ã”ã¨ã®æŒ‡æ¨™è¨ˆç®—ã¨è¡¨ç¤º
        n_classes = cm.shape[0]
        for i in range(n_classes):
            TP = cm[i, i]
            FN = np.sum(cm[i, :]) - TP
            FP = np.sum(cm[:, i]) - TP
            TN = np.sum(cm) - (TP + FN + FP)

            # ã‚¼ãƒ­é™¤ç®—å›é¿
            sensitivity = TP / (TP + FN) if (TP + FN) != 0 else 0
            specificity = TN / (TN + FP) if (TN + FP) != 0 else 0

            # çµæœã‚’è¡¨ç¤º
            st.write(f"ç–¼ç—› {i+1}: æ„Ÿåº¦ = {sensitivity * 100:.2f}%, ç‰¹ç•°åº¦ = {specificity * 100:.2f}%")