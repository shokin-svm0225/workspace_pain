
import streamlit as st
import numpy as np
import pandas as pd
import time
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker

from concurrent.futures import ProcessPoolExecutor, as_completed

from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix
from sklearn.svm import SVC
from sklearn.model_selection import StratifiedKFold
import joblib

# =========================================================
# ğŸ”§ æ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’å£Šã•ãªã„ UI ãƒ¬ã‚¤ãƒ¤ï¼ˆæœ€å°å¤‰æ›´ï¼‰
# =========================================================

def _list_input(label: str, default_text: str, help_text: str = ""):
    txt = st.text_input(label, value=default_text, help=help_text)
    vals = []
    if txt.strip():
        try:
            for x in txt.split(","):
                x = x.strip()
                if any(ch in x for ch in [".", "e", "E"]):
                    vals.append(float(x))
                else:
                    vals.append(int(x))
        except Exception:
            st.warning(f"{label}: æ•°å€¤ã«å¤‰æ›ã§ããªã„è¦ç´ ãŒã‚ã‚Šã¾ã™ã€‚")
    return vals

def _grid_ui():
    st.sidebar.header("æ¢ç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")

    # --- åå¾©å›æ•°ï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«å…±æœ‰ç”¨; é–¢æ•°ãŒå‚ç…§ã™ã‚‹ãªã‚‰ä½¿ã‚ã‚Œã¾ã™ï¼‰ ---
    max_iters = st.sidebar.number_input("ãƒ’ãƒ«ã‚¯ãƒ©ã‚¤ãƒŸãƒ³ã‚°åå¾©å›æ•°", min_value=1, value=200, step=10,
                                        help="é–¢æ•°å†…ã§ã“ã®å€¤ã‚’å‚ç…§ã™ã‚‹å®Ÿè£…ãªã‚‰ã€ã“ã®è¨­å®šãŒé©ç”¨ã•ã‚Œã¾ã™ã€‚")
    st.session_state["max_iters_ui"] = int(max_iters)

    # --- ã‚«ãƒ¼ãƒãƒ«é¸æŠï¼ˆæœ€çµ‚å­¦ç¿’ã«ä½¿ç”¨ã€‚å†…éƒ¨æ¢ç´¢ãŒRBFå‰æã§ã‚‚UIã¯ç¢ºä¿ï¼‰ ---
    kernel_choice = st.sidebar.selectbox("æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã®ã‚«ãƒ¼ãƒãƒ«", ["rbf", "linear", "poly", "sigmoid"], index=0)

    # --- å…±é€šï¼ˆç¾è¡Œ param_grid: step_size, gamma, Cï¼‰ ---
    st.sidebar.subheader("ã‚°ãƒªãƒƒãƒ‰ï¼ˆç¾è¡Œï¼šstep_size Ã— gamma Ã— Cï¼‰")

    step_sizes = _list_input(
        "step_sizeï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰",
        "0.01,0.05",
        "ä¾‹: 0.005,0.01,0.05"
    )

    # ã‚«ãƒ¼ãƒãƒ«åˆ¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆUIã ã‘ã€‚ç¾è¡Œã®æ¢ç´¢ã¯ gamma ã¨ C ã‚’ä½¿ç”¨ï¼‰
    with st.sidebar.expander("RBF: C / gamma", expanded=True):
        C_values_rbf = _list_input("Cï¼ˆRBFï¼‰", "0.1,1,10", "ä¾‹: 0.1,1,10,100")
        gamma_values_rbf = _list_input("gammaï¼ˆRBFï¼‰", "0.01,0.05,0.1", "ä¾‹: 0.001,0.01,0.1,1")

    with st.sidebar.expander("linear: C", expanded=False):
        C_values_linear = _list_input("Cï¼ˆlinearï¼‰", "0.1,1,10", "â€» å‚è€ƒUIï¼ˆå†…éƒ¨ãƒ­ã‚¸ãƒƒã‚¯æœªæ¥ç¶šï¼‰")

    with st.sidebar.expander("poly: C / gamma / coef0 / degree", expanded=False):
        C_values_poly = _list_input("Cï¼ˆpolyï¼‰", "0.1,1,10", "")
        gamma_values_poly = _list_input("gammaï¼ˆpolyï¼‰", "0.001,0.01,0.1", "")
        coef0_values_poly = _list_input("coef0ï¼ˆpolyï¼‰", "0.0,0.5,1.0", "")
        degree_values_poly = _list_input("degreeï¼ˆpolyï¼‰", "2,3,4", "")

    with st.sidebar.expander("sigmoid: C / gamma / coef0", expanded=False):
        C_values_sigmoid = _list_input("Cï¼ˆsigmoidï¼‰", "0.1,1,10", "")
        gamma_values_sigmoid = _list_input("gammaï¼ˆsigmoidï¼‰", "0.001,0.01,0.1", "")
        coef0_values_sigmoid = _list_input("coef0ï¼ˆsigmoidï¼‰", "0.0,0.5,1.0", "")

    # ç¾è¡Œã® param_grid æ§‹ç¯‰ï¼ˆRBFäº’æ›: step_size Ã— gamma Ã— Cï¼‰
    return {
        "max_iters": int(max_iters),
        "kernel_choice": kernel_choice,
        "step_sizes": step_sizes or [0.01],
        "C_values": C_values_rbf or [0.1, 1],
        "gamma_values": gamma_values_rbf or [0.01, 0.05],
        # å‚è€ƒï¼šä¿æŒã—ã¦ãŠãï¼ˆå°†æ¥ã®å†…éƒ¨å¯¾å¿œç”¨ï¼‰
        "grids_all": {
            "rbf": {"C": C_values_rbf, "gamma": gamma_values_rbf},
            "linear": {"C": C_values_linear},
            "poly": {"C": C_values_poly, "gamma": gamma_values_poly, "coef0": coef0_values_poly, "degree": degree_values_poly},
            "sigmoid": {"C": C_values_sigmoid, "gamma": gamma_values_sigmoid, "coef0": coef0_values_sigmoid},
        }
    }

def apply_weights(X: np.ndarray, w: np.ndarray) -> np.ndarray:
    return X * w

# =========================================================
# ğŸ›Ÿ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè£…ï¼ˆrun_hill_climbing ãŒæœªå®šç¾©ãªã‚‰ç”¨æ„ï¼‰
# =========================================================
try:
    run_hill_climbing  # type: ignore[name-defined]
except NameError:
    def _evaluate(weights_change: np.ndarray,
                  datas: np.ndarray,
                  labels: np.ndarray,
                  C: float,
                  gamma: float,
                  k: int = 5,
                  return_best_split: bool = False):
        X_weighted = datas * weights_change
        skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)
        scores = []
        best_fold_score = -np.inf
        best_X_val = best_y_val = best_pred = None

        for train_index, val_index in skf.split(X_weighted, labels):
            X_train, X_val = X_weighted[train_index], X_weighted[val_index]
            y_train, y_val = labels[train_index], labels[val_index]

            model = SVC(C=C, kernel='rbf', gamma=gamma, max_iter=1500)
            model.fit(X_train, y_train)
            y_pred = model.predict(X_val)
            acc = float(np.mean(y_pred == y_val))
            scores.append(acc)

            if return_best_split and acc > best_fold_score:
                best_fold_score = acc
                best_X_val, best_y_val, best_pred = X_val, y_val, y_pred

        if return_best_split:
            return float(np.mean(scores)), best_X_val, best_y_val, best_pred
        else:
            return float(np.mean(scores))

    def _hill_climbing(datas: np.ndarray, labels: np.ndarray,
                       C: float, gamma: float,
                       max_iters: int = None,
                       step_size: float = 0.01):
        # åå¾©å›æ•°ã¯ UI ã®å€¤ã‚’ä½¿ã†ï¼ˆæœªè¨­å®šãªã‚‰ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ200ï¼‰
        if max_iters is None:
            max_iters = int(st.session_state.get("max_iters_ui", 200))

        n_features = datas.shape[1]
        weights_change = np.ones(n_features, dtype=float)

        best_score, best_X_val, best_y_val, best_pred = _evaluate(
            weights_change, datas, labels, C, gamma, k=5, return_best_split=True
        )
        best_weights = weights_change.copy()
        score_history = [best_score]

        global_best_score = best_score
        global_best_weights = best_weights.copy()
        global_best_pack = (best_X_val, best_y_val, best_pred)

        for _ in range(int(max_iters)):
            improved = False
            for j in range(n_features):
                for delta in (+step_size, -step_size):
                    w_try = best_weights.copy()
                    w_try[j] = max(0.0, w_try[j] + delta)
                    score_try = _evaluate(w_try, datas, labels, C, gamma, k=5, return_best_split=False)
                    if score_try > best_score:
                        best_score = score_try
                        best_weights = w_try
                        improved = True

            score_history.append(best_score)

            if best_score > global_best_score:
                global_best_score = best_score
                global_best_weights = best_weights.copy()
                _, Xv, yv, pv = _evaluate(best_weights, datas, labels, C, gamma, k=5, return_best_split=True)
                global_best_pack = (Xv, yv, pv)

            if not improved:
                break

        return global_best_weights, float(global_best_score), global_best_pack[0], global_best_pack[1], global_best_pack[2], score_history

    def run_hill_climbing(step_size: float, gamma: float, C: float, datas: np.ndarray, labels: np.ndarray):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼æ—¢å­˜ã®å‘¼ã³å‡ºã—ã‚·ã‚°ãƒãƒãƒ£ã‚’å°Šé‡ã—ãŸãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆã€‚
        è¿”ã‚Šå€¤ã®ã‚­ãƒ¼ã‚‚æ—¢å­˜ã‚³ãƒ¼ãƒ‰ãŒæœŸå¾…ã™ã‚‹ã‚‚ã®ã«åˆã‚ã›ã‚‹ã€‚
        """
        weights_best, score, X_val_tmp, y_val_tmp, pred_tmp, score_history = _hill_climbing(
            datas, labels, C=C, gamma=gamma, max_iters=int(st.session_state.get("max_iters_ui", 200)), step_size=step_size
        )
        return {
            "step_size": step_size,
            "gamma": gamma,
            "C": C,
            "score": float(score),
            "weights": [float(f"{w:.4f}") for w in weights_best],
            "weights_raw": np.asarray(weights_best, dtype=float).tolist(),
            "score_history": list(map(float, score_history)),
            "X_val": X_val_tmp,
            "y_val": y_val_tmp,
            "pred": pred_tmp,
        }

# =========================================================
# ğŸ§ª ãƒ¡ã‚¤ãƒ³ï¼ˆã‚ãªãŸã®æ—¢å­˜ãƒ–ãƒ­ãƒƒã‚¯ã‚’æœ€å°ç·¨é›†ã§å†…åŒ…ï¼‰
# =========================================================

def main():
    st.title("ğŸ§  Hill Climbing Ã— ä¸¦åˆ—æ¢ç´¢ï¼ˆSVMæœ€é©åŒ–ï¼‰")

    # â–¼â–¼â–¼ ã“ã“ã¯ã‚ãªãŸã®å‰å‡¦ç†ãƒ–ãƒ­ãƒƒã‚¯ã‚’æƒ³å®šï¼ˆã‚³ãƒ”ãƒšã§å·®ã—æ›¿ãˆã¦ãã ã•ã„ï¼‰ â–¼â–¼â–¼
    # ä¾‹ã¨ã—ã¦ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½œã‚Šã¾ã™ã€‚å®Ÿé‹ç”¨ã§ã¯ df1/df2/df3, edited_df ç­‰ã‹ã‚‰ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
    N = 180
    D = 12
    rng = np.random.default_rng(42)
    df1 = pd.DataFrame(rng.normal(0, 1, size=(N//3, D)), columns=[f"F{i+1}" for i in range(D)])
    df2 = pd.DataFrame(rng.normal(0.5, 1, size=(N//3, D)), columns=[f"F{i+1}" for i in range(D)])
    df3 = pd.DataFrame(rng.normal(-0.5, 1, size=(N - 2*(N//3), D)), columns=[f"F{i+1}" for i in range(D)])

    stocks = df1.columns.tolist()
    edited_df = pd.DataFrame({"columns": stocks, "weights": np.ones(len(stocks))})

    choice_4 = st.selectbox("æ¨™æº–åŒ–ã‚’è¡Œã†ï¼Ÿ", ["ã™ã‚‹", "ã—ãªã„"], index=0)

    columns = edited_df["columns"].tolist()
    weights = edited_df["weights"].tolist()

    df_nociceptive_train = df1[columns]
    df_neuronociceptive_train = df2[columns]
    df_unknown_train = df3[columns]

    df_nociceptive_train_weighted = df_nociceptive_train.mul(weights, axis=1)
    df_neuronociceptive_train_weighted = df_neuronociceptive_train.mul(weights, axis=1)
    df_unknown_train_weighted = df_unknown_train.mul(weights, axis=1)

    datas = np.vstack(
        [
            df_nociceptive_train_weighted.values,
            df_neuronociceptive_train_weighted.values,
            df_unknown_train_weighted.values,
        ]
    ).astype(np.float32)

    labels1 = np.full(len(df_nociceptive_train_weighted), 1, np.int32)
    labels2 = np.full(len(df_neuronociceptive_train_weighted), 2, np.int32)
    labels3 = np.full(len(df_unknown_train_weighted), 3, np.int32)
    labels = np.concatenate([labels1, labels2, labels3]).astype(np.int32)

    if choice_4 == "ã™ã‚‹":
        scaler = StandardScaler()
        datas = scaler.fit_transform(datas)

    # â–²â–²â–² ã‚ãªãŸã®å‰å‡¦ç†ã“ã“ã¾ã§ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ã«ç½®æ›ï¼‰ â–²â–²â–²

    # --- æ–°ã—ã„ UI ã§æ¢ç´¢æ¡ä»¶ã‚’è¨­å®šï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã¯ä¿æŒï¼‰ ---
    ui = _grid_ui()

    # === ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š & å®Ÿè¡Œï¼ˆã‚ãªãŸã®å…ƒã‚³ãƒ¼ãƒ‰ã‚’è¸è¥²ï¼‰ ===
    step_sizes = ui["step_sizes"]
    C_values = ui["C_values"]
    gamma_values = ui["gamma_values"]

    param_grid = [
        (step_size, gamma, C)
        for step_size in step_sizes
        for gamma in gamma_values
        for C in C_values
    ]

    all_results = []
    best_score = 0.0
    best_result = None

    st.write("ğŸ” ä¸¦åˆ—å®Ÿè¡Œä¸­...")

    start_time = time.time()

    with ProcessPoolExecutor(max_workers=8) as executor:
        futures = {
            executor.submit(run_hill_climbing, step_size, gamma, C, datas, labels):
            (step_size, gamma, C)
            for (step_size, gamma, C) in param_grid
        }
        total_jobs = len(futures)

        done = 0
        progress_bar = st.progress(0)
        progress_text = st.empty()

        for future in as_completed(futures):
            result = future.result()
            all_results.append(result)

            if result["score"] > best_score:
                best_score = result["score"]
                best_result = result

            done += 1
            percent = int(done / total_jobs * 100) if total_jobs else 100
            progress_bar.progress(percent, text=f"é€²æ—çŠ¶æ³ {done}/{total_jobs}ï¼ˆ{percent}ï¼…ï¼‰")
            progress_text.text(f"é€²æ—çŠ¶æ³ {done}/{total_jobs}")

    results_df = pd.DataFrame([{
        "step_size": r["step_size"],
        "gamma": r["gamma"],
        "C": r["C"],
        "score": r["score"],
        "weights": r["weights"]
    } for r in all_results])

    elapsed = time.time() - start_time
    st.write(f"â± å®Ÿè¡Œæ™‚é–“: {elapsed:.2f} ç§’")

    st.subheader("ğŸ“Š ã‚¹ã‚³ã‚¢ã¾ã¨ã‚")
    st.dataframe(results_df.sort_values(by="score", ascending=False), use_container_width=True)

    st.subheader("ğŸ“ˆ ä¸€ç•ªè‰¯ã‹ã£ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚¹ã‚³ã‚¢æ¨ç§»")
    if best_result is None:
        st.warning("çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ¢ç´¢æ¡ä»¶ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
        return

    best_history = best_result["score_history"]
    fig, ax = plt.subplots()
    ax.plot(range(len(best_history)), best_history)
    ax.set_title("Best Score Progression by Hill Climbing")
    ax.set_xlabel("Step")
    ax.set_ylabel("Score")
    ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))
    st.pyplot(fig)

    # === æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ï¼ˆUI ã®ã‚«ãƒ¼ãƒãƒ«é¸æŠã‚’é©ç”¨ï¼‰ ===
    st.subheader("ğŸ§© æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ»ä¿å­˜")
    kernel_for_final = ui["kernel_choice"]

    X_weighted_final = apply_weights(datas, np.array(best_result["weights"], dtype=float))

    gamma_final = best_result.get("gamma", None)
    C_final = best_result.get("C", 1.0)
    coef0_final = 0.0
    degree_final = 3

    final_model = SVC(
        C=C_final,
        kernel=kernel_for_final,
        gamma=gamma_final if kernel_for_final in ("rbf", "poly", "sigmoid") else "scale",
        coef0=coef0_final if kernel_for_final in ("poly", "sigmoid") else 0.0,
        degree=degree_final if kernel_for_final == "poly" else 3,
        max_iter=1500
    )
    final_model.fit(X_weighted_final, labels)
    joblib.dump(final_model, "final_model.joblib")
    st.success("âœ… æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ˆfinal_model.joblibï¼‰")

    # === æ„Ÿåº¦ãƒ»ç‰¹ç•°åº¦ã®è¨ˆç®—ï¼ˆCV ã®ãƒ™ã‚¹ãƒˆ fold ã‚’ä½¿ç”¨ï¼‰ ===
    st.subheader("ğŸ§® æ„Ÿåº¦ãƒ»ç‰¹ç•°åº¦")
    best_y_val = best_result["y_val"]
    best_pred = best_result["pred"]
    if best_y_val is not None and best_pred is not None:
        conf_matrix = confusion_matrix(best_y_val, best_pred, labels=[1, 2, 3])
        n_classes = conf_matrix.shape[0]
        for i in range(n_classes):
            TP = conf_matrix[i, i]
            FN = np.sum(conf_matrix[i, :]) - TP
            FP = np.sum(conf_matrix[:, i]) - TP
            TN = np.sum(conf_matrix) - (TP + FN + FP)
            sensitivity = TP / (TP + FN) if (TP + FN) != 0 else 0
            specificity = TN / (TN + FP) if (TN + FP) != 0 else 0
            st.write(f"ç–¼ç—› {i+1}: æ„Ÿåº¦ = {sensitivity * 100:.2f}%, ç‰¹ç•°åº¦ = {specificity * 100:.2f}%")
    else:
        st.info("ãƒ™ã‚¹ãƒˆfoldã®äºˆæ¸¬ãŒç„¡ã„ã®ã§æ„Ÿåº¦ãƒ»ç‰¹ç•°åº¦ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")

if __name__ == "__main__":
    main()
